{"content": "<!DOCTYPE HTML>\n<html lang=\"en-gb\" class=\"no-js\">\n    <head>\n        <meta charset=\"utf-8\">\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge,chrome=1\"/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=2.5,user-scalable=yes\">\n    <meta name=\"citation_publisher\" content=\"Springer, Cham\"/>\n    <meta name=\"citation_title\" content=\"The Exploration of User Knowledge Architecture Based on Mining User Generated Contents \u2013 An Application Case of Photo-Sharing Website\"/>\n    <meta name=\"citation_doi\" content=\"10.1007/978-3-319-40406-6_17\"/>\n    <meta name=\"citation_language\" content=\"en\"/>\n    <meta name=\"citation_abstract_html_url\" content=\"https://link.springer.com/chapter/10.1007/978-3-319-40406-6_17\"/>\n    <meta name=\"citation_fulltext_html_url\" content=\"https://link.springer.com/chapter/10.1007/978-3-319-40406-6_17\"/>\n    <meta name=\"citation_pdf_url\" content=\"https://link.springer.com/content/pdf/10.1007%2F978-3-319-40406-6_17.pdf\"/>\n    <meta name=\"citation_springer_api_url\" content=\"http://api.springer.com/metadata/pam?q=doi:10.1007/978-3-319-40406-6_17&amp;api_key=\"/>\n    <meta name=\"citation_firstpage\" content=\"180\"/>\n    <meta name=\"citation_lastpage\" content=\"192\"/>\n    <meta name=\"citation_author\" content=\"Liang, Nan\"/>\n    <meta name=\"citation_author_institution\" content=\"S.J.T.U.\"/>\n    <meta name=\"citation_author\" content=\"Zhong, Jiaming\"/>\n    <meta name=\"citation_author_institution\" content=\"S.J.T.U.\"/>\n    <meta name=\"citation_author\" content=\"Wang, Di\"/>\n    <meta name=\"citation_author_institution\" content=\"S.J.T.U.\"/>\n    <meta name=\"citation_author\" content=\"Zhang, Liqun\"/>\n    <meta name=\"citation_author_institution\" content=\"S.J.T.U.\"/>\n    <meta name=\"citation_author_email\" content=\"zhanglq@sjtu.edu.cn\"/>\n    <meta name=\"dc.identifier\" content=\"10.1007/978-3-319-40406-6_17\"/>\n    <meta name=\"format-detection\" content=\"telephone=no\"/>\n    <meta name=\"citation_fulltext_world_readable\" content=\"\"/>\n    <meta name=\"description\" content=\"Traditional methods to obtain user needs, such as interview, have exposed the increasingly serious problem of bias and inefficiency when meeting the blooming of users. This research tried to...\"/>\n    <meta name=\"twitter:card\" content=\"summary\"/>\n    <meta name=\"twitter:title\" content=\"The Exploration of User Knowledge Architecture Based on Mining User Ge\"/>\n    <meta name=\"twitter:image\" content=\"https://static-content.springer.com/cover/book/978-3-319-40406-6.jpg\"/>\n    <meta name=\"twitter:image:alt\" content=\"Content cover image\"/>\n    <meta name=\"twitter:site\" content=\"SpringerLink\"/>\n    <meta name=\"twitter:description\" content=\"Traditional methods to obtain user needs, such as interview, have exposed the increasingly serious problem of bias and inefficiency when meeting the blooming of users. This research tried to...\"/>\n    <meta name=\"citation_inbook_title\" content=\"Design, User Experience, and Usability: Technological Contexts\"/>\n    <meta name=\"citation_publication_date\" content=\"2016/7/17\"/>\n    <meta name=\"citation_conference_series_id\" content=\"springer/duxu\"/>\n    <meta name=\"citation_conference_title\" content=\"International Conference of Design, User Experience, and Usability\"/>\n    <meta name=\"citation_conference_sequence_num\" content=\"5\"/>\n    <meta name=\"citation_conference_abbrev\" content=\"DUXU\"/>\n    <meta property=\"og:title\" content=\"The Exploration of User Knowledge Architecture Based on Mining User Generated Contents \u2013 An Application Case of Photo-Sharing Website\"/>\n    <meta property=\"og:type\" content=\"Paper\"/>\n    <meta property=\"og:url\" content=\"https://link.springer.com/chapter/10.1007/978-3-319-40406-6_17\"/>\n    <meta property=\"og:image\" content=\"https://static-content.springer.com/cover/book/978-3-319-40406-6.jpg\"/>\n    <meta property=\"og:site_name\" content=\"SpringerLink\"/>\n    <meta property=\"og:description\" content=\"Traditional methods to obtain user needs, such as interview, have exposed the increasingly serious problem of bias and inefficiency when meeting the blooming of users. This research tried to...\"/>\n\n        <title>The Exploration of User Knowledge Architecture Based on Mining User Generated Contents \u2013 An Application Case of Photo-Sharing Website | SpringerLink</title>\n        <link rel=\"canonical\" href=\"https://link.springer.com/chapter/10.1007/978-3-319-40406-6_17\"/>\n        <link rel=\"shortcut icon\" href=\"/springerlink-static/1923692707/images/favicon/favicon.ico\">\n<link rel=\"icon\" sizes=\"16x16 32x32 48x48\" href=\"/springerlink-static/1923692707/images/favicon/favicon.ico\">\n<link rel=\"icon\" sizes=\"16x16\" type=\"image/png\" href=\"/springerlink-static/1923692707/images/favicon/favicon-16x16.png\">\n<link rel=\"icon\" sizes=\"32x32\" type=\"image/png\" href=\"/springerlink-static/1923692707/images/favicon/favicon-32x32.png\">\n<link rel=\"icon\" sizes=\"48x48\" type=\"image/png\" href=\"/springerlink-static/1923692707/images/favicon/favicon-48x48.png\">\n<link rel=\"apple-touch-icon\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-iphone@3x.png\">\n<link rel=\"apple-touch-icon\" sizes=\"72x72\" href=\"/springerlink-static/1923692707/images/favicon/ic_launcher_hdpi.png\">\n<link rel=\"apple-touch-icon\" sizes=\"76x76\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-ipad.png\">\n<link rel=\"apple-touch-icon\" sizes=\"114x114\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-114x114.png\">\n<link rel=\"apple-touch-icon\" sizes=\"120x120\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-iphone@2x.png\">\n<link rel=\"apple-touch-icon\" sizes=\"144x144\" href=\"/springerlink-static/1923692707/images/favicon/ic_launcher_xxhdpi.png\">\n<link rel=\"apple-touch-icon\" sizes=\"152x152\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-ipad@2x.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-iphone@3x.png\">\n<meta name=\"msapplication-TileColor\" content=\"#ffffff\">\n<meta name=\"msapplication-TileImage\" content=\"/springerlink-static/1923692707/images/favicon/ic_launcher_xxhdpi.png\">\n        <link rel=\"dns-prefetch\" href=\"//fonts.gstatic.com\">\n<link rel=\"dns-prefetch\" href=\"//fonts.googleapis.com\">\n<link rel=\"dns-prefetch\" href=\"//google-analytics.com\">\n<link rel=\"dns-prefetch\" href=\"//www.google-analytics.com\">\n<link rel=\"dns-prefetch\" href=\"//www.googletagservices.com\">\n<link rel=\"dns-prefetch\" href=\"//www.googletagmanager.com\">\n<link rel=\"dns-prefetch\" href=\"//static-content.springer.com\">\n        <link rel=\"stylesheet\" href=\"/springerlink-static/1923692707/css/basic.css\" media=\"screen\">\n<link rel=\"stylesheet\" href=\"/springerlink-static/1923692707/css/styles.css\" class=\"js-ctm\" media=\"only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)\">\n<link rel=\"stylesheet\" href=\"/springerlink-static/1923692707/css/print.css\" media=\"print\">\n\n\n        <script>\n    (function () {\n        if ( typeof window.CustomEvent === \"function\" ) return;\n        window.CustomEvent = function ( event, params ) {\n            params = params || { bubbles: false, cancelable: false, detail: null };\n            var evt = document.createEvent( 'CustomEvent' );\n            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );\n            return evt;\n        }\n    })();\n</script>\n\n<script>\n    (function() {\n        if (!!document.documentElement.dataset) return;\n\n        Object.defineProperty(Element.prototype, 'dataset', {\n            get: function() {\n                var element = this;\n                var attributes = this.attributes;\n                var map = {};\n\n                for (var i = 0; i < attributes.length; i++) {\n                    var attribute = attributes[i];\n\n                    if (attribute && attribute.name && (/^data-\\w[\\w-]*$/).test(attribute.name)) {\n                        var name = attribute.name;\n                        var value = attribute.value;\n\n                        var propName = name.substr(5).replace(/-./g, function (prop) {\n                            return prop.charAt(1).toUpperCase();\n                        });\n\n                        Object.defineProperty(map, propName, {\n                            enumerable: true,\n                            get: function() {\n                                return this.value;\n                            }.bind({value: value || ''}),\n                            set: function setter(name, value) {\n                                if (typeof value !== 'undefined') {\n                                    this.setAttribute(name, value);\n                                } else {\n                                    this.removeAttribute(name);\n                                }\n                            }.bind(element, name)\n                        });\n                    }\n                }\n\n                return map;\n            }\n        });\n    })();\n</script>\n\n\n\n    <script type=\"text/javascript\">\n        window.Krux||((Krux=function(){Krux.q.push(arguments);}).q=[]);\n        var dataLayer = [{\n                'GA Key':\"UA-26408784-1\",\n                'Features':[\"leaderboardadverts\",\"eventtracker\"],\n                'Event Category':\"Conference Paper\",\n                'Open Access':\"N\",\n                'Labs':\"Y\",\n                'DOI':\"10.1007/978-3-319-40406-6_17\",\n                'productId':\"9783319404066\",\n                'hasAccess':\"Y\",\n                'Full HTML':\"Y\",\n                'Has Body':\"Y\",\n                'Static Hash':\"1923692707\",\n                'Has Preview':\"N\",\n                'user':{\"license\":{\"businessPartnerID\":[],\"businessPartnerIDString\":\"\"}},\n                'content':{\"serial\":{\"eissn\":\"1611-3349\",\"pissn\":\"0302-9743\"},\"book\":{\"seriesTitle\":\"Lecture Notes in Computer Science\",\"eisbn\":\"978-3-319-40406-6\",\"pisbn\":\"978-3-319-40405-9\",\"bookProductType\":\"Proceedings\",\"seriesId\":\"558\",\"title\":\"Design, User Experience, and Usability: Technological Contexts\",\"doi\":\"10.1007/978-3-319-40406-6\"},\"attributes\":{\"deliveryPlatform\":\"bunsen\"},\"chapter\":{\"doi\":\"10.1007/978-3-319-40406-6_17\"},\"category\":{\"pmc\":{\"primarySubject\":\"Computer Science\",\"primarySubjectCode\":\"I\",\"secondarySubjects\":{\"4\":\"Information Storage and Retrieval\",\"5\":\"Software Engineering\",\"1\":\"User Interfaces and Human Computer Interaction\",\"2\":\"Computers and Society\",\"3\":\"Information Systems Applications (incl. Internet)\"},\"secondarySubjectCodes\":{\"4\":\"I18032\",\"5\":\"I14029\",\"1\":\"I18067\",\"2\":\"I24040\",\"3\":\"I18040\"}},\"sucode\":\"SUCO11645\"},\"type\":\"ConferencePaper\"},\n                'Access Type':\"subscription\",\n                'Page':\"chapter\",\n                'Bpids':\"\",\n                'Bpnames':\"\",\n                'SubjectCodes':\"SCI, SCI18067, SCI24040, SCI18040, SCI18032, SCI14029\",\n                'session':{\"authentication\":{\"loginStatus\":\"N\"},\"attributes\":{\"edition\":\"academic\"}},\n                'eventTrackerBaseUrl':\"https://event-tracker.springernature.com\",\n                'Keywords':\"Image, Content analysis, User knowledge, Experience, Photo sharing site\",\n                'Country':\"BR\",\n                'ConferenceSeriesId':\"duxu\",\n                'VG Wort Identifier':\"vgzm.415900-10.1007-978-3-319-40406-6\",\n\n                    'doi': \"10.1007-978-3-319-40406-6_17\",\n                    'kwrd': [\"Image\",\"Content_analysis\",\"User_knowledge\",\"Experience\",\"Photo_sharing_site\"],\n                    'pmc': [\"I\",\"I18067\",\"I24040\",\"I18040\",\"I18032\",\"I14029\"],\n                    'BPID': [\"1\"],\n                    'ksg': Krux.segments,\n                    'kuid': Krux.uid,\n\n        }];\n    </script>\n    <script>\n        window.dataLayer.push({\n            content: {\n                attributes: {\n                    deliveryPlatform: \"bunsen\"\n                }\n            }\n        });\n    </script>\n\n<script type=\"text/javascript\" src=\"/springerlink-static/1923692707/js/jquery-3.3.1.min.js\"></script>\n\n<script>\n    (function() {\n        function deleteCookie (name, domain) {\n            document.cookie = encodeURIComponent(name) +\n                '=' +\n                ';path=/' +\n                ';domain=' + domain +\n                ';expires=Thu, 01 Jan 1970 00:00:00 GMT';\n        }\n\n        var consentCookieParts = ('; ' + document.cookie).split('; OptanonConsent=');\n\n        if (consentCookieParts.length > 1) {\n            consentCookieParts.shift(); // remove redundant first part from the split array\n\n            // onetrust can set the same cookie multiple times with different domain specificities\n            for (let i=0; i<consentCookieParts.length; i++) {\n                var otCookieGroups = consentCookieParts[i].split('&groups=').pop().split('&').shift();\n\n                if (otCookieGroups.indexOf('C0001') === -1) {\n                    deleteCookie('OptanonConsent', window.location.host);\n                    deleteCookie('OptanonAlertBoxClosed', window.location.host);\n                }\n            }\n        }\n    })();\n</script>\n\n<script>\n    (function(w,d,t) {\n        function cc() {\n            var h = w.location.host, id;\n            if (h === 'link.springer.com' || h === 'local-link.springer.com' || h === 'link-qa.springer.com') { id = '4f53bc14-4ee3-45bd-9935-e3d2b6b2a543'}\n            if (h === 'rd.springer.com' || h === 'local-rd.springer.com' || h === 'rd-qa.springer.com') { id = 'ee0bb2c1-7bb6-4b9a-bbfe-41fc45438f37'}\n            var e = d.createElement(t),\n                s = d.getElementsByTagName(t)[0];\n            if (id) {\n                e.src = 'https://cdn.cookielaw.org/scripttemplates/otSDKStub.js';\n                e.setAttribute('data-domain-script', id);\n            } else {\n                e.src = '/static/js/lib/cookie-consent.min.js';\n                e.setAttribute('data-consent', h);\n            }\n            s.parentNode.insertBefore(e, s);\n        }\n        w.google_tag_manager ? cc() : window.addEventListener('gtm_loaded', function() {cc()});\n    })(window,document,'script');\n</script>\n<script>\n    function OptanonWrapper() {\n        window.dataLayer.push({ event:'OneTrustGroupsUpdated' });\n        document.activeElement.blur();\n    }\n</script>\n\n    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\n                new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\n            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n            'https://www.googletagmanager.com/gtm.js?id='+i+dl;\n\n            j.addEventListener('load', function() {\n                var _ge = new CustomEvent('gtm_loaded', {bubbles: true});\n                d.dispatchEvent(_ge);\n            });\n\n            f.parentNode.insertBefore(j,f);\n    })(window,document,'script','dataLayer','GTM-WCF9Z9');</script>\n\n\n    </head>\n    <body>\n        <noscript><iframe src=\"//www.googletagmanager.com/ns.html?id=GTM-WCF9Z9\"\n                      height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>\n\n    <div class=\"skip-to\">\n    <a class=\"skip-to__link pseudo-focus\" href=\"#main-content\">Skip to main content</a>\n        <a class=\"skip-to__link skip-to__link--contents pseudo-focus\" href=\"#article-contents\">Skip to sections</a>\n</div>\n        <div class=\"page-wrapper\">\n            <noscript>\n    <div class=\"nojs-banner u-interface\">\n        <p>This service is more advanced with JavaScript available</p>\n    </div>\n</noscript>\n                        <div id=\"leaderboard\" class=\"leaderboard u-hide\" data-google-ad=\"leaderboard\" data-gpt-hide-ad>\n            <div class=\"leaderboard__wrapper\">\n                <p class=\"leaderboard__label\">Advertisement</p>\n                <button class=\"leaderboard__hide\" title=\"Hide this advertisement\" data-gpt-hide-ad-button data-track=\"click\" data-track-action=\"Hide advertisement\" data-track-label=\"\">Hide</button>\n                <div id=\"doubleclick-leaderboard-ad\" class=\"leaderboard__ad u-pt-24\" data-gpt></div>\n            </div>\n        </div>\n\n\n                <header id=\"header\" class=\"header\">\n        <div class=\"header__content\">\n            <div class=\"header__menu-container\">\n                    <a id=\"logo\" class=\"site-logo\" href=\"/\" title=\"Go to homepage\">\n            <picture>\n    <source type=\"image/svg+xml\" srcset=\"/springerlink-static/1923692707/images/svg/springerlink.svg\">\n    <img class=\"site-logo__springer\" src=\"/springerlink-static/1923692707/images/png/springerlink.png\" alt=\"SpringerLink\" width=\"148\" height=\"30\" data-test=\"springer-logo\">\n</picture>\n\n    </a>\n\n\n                    <nav id=\"search-container\" class=\"u-inline-block\">\n                        <div class=\"search\">\n                            <div class=\"search__content\">\n                                <form class=\"u-form-single-input u-system\" action=\"/search\" method=\"get\" role=\"search\">\n    <label for=\"search-springerlink\">Search SpringerLink</label>\n    <div class=\"u-relative\">\n        <input id=\"search-springerlink\" name=\"query\" type=\"text\" autocomplete=\"off\" value=\"\">\n        <input class=\"u-hide-text\" type=\"submit\" value=\"Submit\" title=\"Submit\">\n        <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"13\" height=\"13\" class=\"u-vertical-align-absolute\" focusable=\"false\" aria-hidden=\"true\" role=\"presentation\">\n            <path d=\"M12.82 11.972a.607.607 0 01.007.856.611.611 0 01-.856-.006L9.45 10.3A5.798 5.797 0 010 5.798 5.798 5.797 0 1110.3 9.45zm-7.022-1.205A4.97 4.97 0 105.797.83a4.97 4.97 0 000 9.939z\" fill-rule=\"evenodd\"/>\n        </svg>\n    </div>\n</form>\n                            </div>\n                        </div>\n                    </nav>\n\n                    <nav class=\"nav-container\">\n    <div class=\"global-nav__wrapper\">\n        <div class=\"search-button\">\n            <a class=\"search-button__label\" href=\"#search-container\">\n                <span class=\"search-button__title\">Search</span>\n                <svg class=\"u-vertical-align-absolute\" xmlns=\"http://www.w3.org/2000/svg\" height=\"22\" width=\"22\" focusable=\"false\" aria-hidden=\"true\" role=\"presentation\">\n                    <path fill-rule=\"evenodd\" d=\"M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z\"/>\n                </svg>\n            </a>\n        </div>\n\n        <ul class=\"global-nav\" data-component=\"SV.Menu\" data-title=\"Navigation menu\" data-text=\"Menu\">\n            <li>\n                <a href=\"/\">\n                    <span class=\"u-overflow-ellipsis\">Home</span>\n                </a>\n            </li>\n\n                <li class=\"global-nav__logged-out\">\n                    <a class=\"test-login-link\" href=\"//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%252F978-3-319-40406-6_17\">\n                        <span class=\"u-overflow-ellipsis\">Log in</span>\n                    </a>\n                </li>\n\n        </ul>\n    </div> \n</nav> \n\n            </div>\n\n        </div>\n    </header>\n\n            \n            <main id=\"main-content\" class=\"main-wrapper main-wrapper--no-gradient\" tabindex=\"-1\">\n                <div class=\"main-container uptodate-recommendations-off\">\n                    <aside class=\"main-sidebar-left\">\n                        <div class=\"main-sidebar-left__content\">\n                            <div class=\"cover-image test-cover\" itemscope>\n                                    <a class=\"test-cover-link\" href=\"/book/10.1007/978-3-319-40406-6\">\n        <span class=\"u-screenreader-only\">Design, User Experience, and Usability: Technological Contexts</span>\n        <img class=\"test-cover-image\" src=\"https://media.springernature.com/w306/springer-static/cover/book/978-3-319-40406-6.jpg\" itemprop=\"image\" alt=\"\"/>\n    </a>\n\n\n\n                            </div>\n                        </div>\n                    </aside>\n                    <div class=\"main-body\" data-role=\"NavigationContainer\">\n                        \n\n\n\n                        <article class=\"main-body__content\">\n                            <div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"FulltextWrapper\"><div class=\"ArticleHeader main-context\"><div id=\"enumeration\" class=\"enumeration\">    <div>\n        <a data-test=\"ConfSeriesLink\" href=\"/conference/duxu\">\n            <span data-test=\"ConfSeriesName\"> International Conference of Design, User Experience, and Usability</span>\n        </a>\n    </div>\n<p class=\"test-LocationInConferenceProceeding icon--meta-keyline\"><span data-test=\"ConferenceAcronym\">DUXU 2016</span>: <span class=\"BookTitle\"><a href=\"/book/10.1007/978-3-319-40406-6\" data-track=\"click\" data-track-action=\"Book title\" data-track-label=\"\">Design, User Experience, and Usability: Technological Contexts</a></span><span class=\"page-numbers-info\">\n                pp 180-192</span><span class=\"u-inline-block u-ml-4\"> |\n                <a href=\"#citeas\" data-track=\"click\" data-track-action=\"Cite as link\" data-track-label=\"Enumeration section\">Cite as</a></span></p></div><div class=\"MainTitleSection\"><h1 class=\"ChapterTitle\" lang=\"en\">The Exploration of User Knowledge Architecture Based on Mining User Generated Contents \u2013 An Application Case of Photo-Sharing Website</h1></div><div class=\"authors u-clearfix\" data-component=\"SpringerLink.Authors\"><ul class=\"u-interface u-inline-list authors__title\" data-role=\"AuthorsNavigation\"><li><span>Authors</span></li><li><a href=\"#authorsandaffiliations\" data-track=\"click\" data-track-action=\"Authors and affiliations tab\" data-track-label=\"\">Authors and affiliations</a></li></ul><div class=\"authors__list\" data-role=\"AuthorsList\"><ul class=\"test-contributor-names\"><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors__name\">Nan\u00a0Liang</span></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors__name\">Jiaming\u00a0Zhong</span></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors__name\">Di\u00a0Wang</span></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors__name\">Liqun\u00a0Zhang</span><span class=\"author-information\"><span class=\"authors__contact\"><a href=\"mailto:zhanglq@sjtu.edu.cn\" title=\"zhanglq@sjtu.edu.cn\" itemprop=\"email\" data-track=\"click\" data-track-action=\"Email author\" data-track-label=\"\"><img src=\"/springerlink-static/images/svg/email.svg\" height=\"24\" width=\"24\" alt=\"Email author\" /></a></span></span></li></ul></div></div><div class=\"main-context__container\" data-component=\"SpringerLink.ArticleMetrics\"><div class=\"main-context__column\"><span><span class=\"test-render-category\">Conference paper</span></span><div class=\"article-dates\"><span class=\"article-dates__label\">First Online: </span><span class=\"article-dates__first-online\"><time datetime=\"2016-06-22\">22 June 2016</time></span></div></div><div class=\"main-context__column\">    <ul id=\"book-metrics\" class=\"article-metrics u-sansSerif\">\n            <li class=\"article-metrics__item\">\n                    <a class=\"article-metrics__link gtm-chaptercitations-count\" href=\"https://citations.springer.com/item?doi&#x3D;10.1007/978-3-319-40406-6_17\" target=\"_blank\" rel=\"noopener\"\n                       title=\"Visit Springer Citations for full citation details\" id=\"chaptercitations-link\">\n                            <span id=\"chaptercitations-count-number\" class=\"test-metric-count c-button-circle gtm-chaptercitations-count\">2</span>\n                       <span class=\"test-metric-name article-metrics__label gtm-chaptercitations-count\">Citations</span>\n                    </a>\n            </li>\n            <li class=\"article-metrics__item\">\n                     <span class=\"test-metric-count article-metrics__views\">1.8k</span>\n                     <span class=\"test-metric-name article-metrics__label\">Downloads</span>\n            </li>\n    </ul>\n</div></div><span id=\"test-SeriesTitle\" class=\"vol-info\">\n                Part of the\n                <a class=\"gtm-book-series-link\" href=\"/bookseries/558\">Lecture Notes in Computer Science</a>\n                book series (LNCS, volume 9748)</span></div><section class=\"Abstract\" id=\"Abs1\" tabindex=\"-1\" lang=\"en\"><h2 class=\"Heading\">Abstract</h2><p id=\"Par1\" class=\"Para\">Traditional methods to obtain user needs, such as interview, have exposed the increasingly serious problem of bias and inefficiency when meeting the blooming of users. This research tried to ameliorate the situation by mining user-generated data and constructing corresponding user knowledge systems with the help of modern technologies. With a photo-sharing website as a study case, several techniques have been implemented, including image feature extraction, content analysis and statistical calculation, to analyze users\u2019 characteristics and preferences. The results indicated that many of these techniques are practical and effective for future research in user experience design. It is foreseeable that the domain of this research can be expanded to text and voice to construct a synthesis approach for ultimately understanding users.</p></section><div class=\"KeywordGroup\" lang=\"en\"><h2 class=\"Heading\">Keywords</h2><span class=\"Keyword\">Image\u00a0</span><span class=\"Keyword\">Content analysis\u00a0</span><span class=\"Keyword\">User knowledge\u00a0</span><span class=\"Keyword\">Experience\u00a0</span><span class=\"Keyword\">Photo sharing site\u00a0</span></div><div class=\"note test-pdf-link\" id=\"cobranding-and-download-availability-text\"><div>    <a href=\"/content/pdf/10.1007%2F978-3-319-40406-6_17.pdf\" target=\"_blank\" rel=\"noopener\" data-track=\"click\" data-track-action=\"Pdf download\" data-track-label=\"\">Download</a>\n conference paper PDF</div></div><div class=\"article-actions--inline\" id=\"article-actions--inline\" data-component=\"article-actions--inline\"></div><div id=\"body\"><section id=\"Sec1\" tabindex=\"-1\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\"><span class=\"HeadingNumber\">1 </span>Introduction</h2><div class=\"content\"><p id=\"Par2\" class=\"Para\">In view of the considerable improvement of material living standard in recent years, designers begin to pay more attention to emotional and spiritual elements in their products and services. The major consideration of user experience design, or UED, is to create satisfying, aesthetic and innovative products which constantly meet user\u2019s needs and even lead the trend of modern lifestyle. Therefore, it is important for designers to understand user needs and further translate them into appropriate products. In the age of the Internet, the presence of blogs, forums, wiki, SNS and RSS combining with newly developed theories such as Six Degrees of Separation and the Long Tail, has made user knowledge into an open, complex and adaptive system. In the current web environment, there is an increasing diversity in the representing forms of user knowledge, while users usually feel easy to accommodate this situation. The problem is left to designers on both acquiring user knowledge and constructing corresponding systems.</p><p id=\"Par3\" class=\"Para\">The key of user research is mining the needs buried deeply in users\u2019 mind through their language and daily behavior. Traditional methods, including questionnaire, interview, observation, focus group and persona, achieve the goal through behavior observation and carefully designed conversation. Designers are required to have empathy and an open mind throughout the process. Otherwise, bad expressions may lead to different or even opposite answers, deviating from user\u2019s reality.</p><p id=\"Par4\" class=\"Para\">To certain extent, traditional methods reveal user needs, but suffer from poor efficiency and non-negligible influence of mood and environment. Hence, they are not suitable for researching on massive users. On the other hand, the original knowledge produced by users themselves better expresses their real thought. Big data technology has made it possible and cheaper to study large groups of users. Till now, it is frequently used in many fields like finance, online business, healthcare, social security and smart city, comparatively rare in that of design.</p><p id=\"Par5\" class=\"Para\">Data mining can be a new aspect for extending the study of user experience and user knowledge. This paper describes how to dig for user knowledge and understand their needs by large-scale data searching and image content analysis technologies and finally construct user knowledge system which ensures excellent user experience. The methods described in this paper are also good references to other design research.</p></div></section><section id=\"Sec2\" tabindex=\"-1\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\"><span class=\"HeadingNumber\">2 </span>Methodology Description</h2><div class=\"content\"><section id=\"Sec3\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">2.1 </span>Overview</h3><div id=\"Par6\" class=\"Para\">This paper mainly elucidate how we apply image feature recognition and content analysis technologies to obtain research variables, which are later estimated by statistical calculation, in order to acquire user knowledge and construct corresponding system. The detailed research process is as follows:<div class=\"UnorderedList\"><ul class=\"UnorderedListMarkBullet\"><li> <p id=\"Par7\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">How to acquire user knowledge?</strong> When using certain products or services, users would exchange information (namely words, images and voice) and this information could be recognized as \u201cuser knowledge\u201d since they directly reflect users\u2019 demands. For instance, users of photo sharing social websites interact with each other by uploading images, clicking \u201clike\u201d, commenting and reposting. In the process of this type of interactions, users undoubtedly leave \u201cinternet footprints\u201d as a part of user knowledge, which manifest their attention and preference.</p> </li><li> <p id=\"Par8\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">How to acquire users\u2019 footprints?</strong> In short, one could apply respective techniques to figure out the footprints left by users. For example, equipped with public programming interfaces exposed by relevant websites (e.g. WeChat API) and web crawler programs, one is able to get users\u2019 information such as images, texts, and voice, under certain agreement of privacy. The emerging of new technologies fulfills the purpose of image analysis, broadening the area of information capture and analysis.</p> </li><li> <p id=\"Par9\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Analysis methodology and tools.</strong> Three main methods have been exploited, including image feature identification, content analysis and statistical calculation.</p> </li></ul></div></div></section><section id=\"Sec4\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">2.2 </span>Details of Three Methods</h3><p id=\"Par10\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Image Feature Recognition.</strong> Three particular tools fall into this category.</p><p id=\"Par11\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Analyzing tools for color spatial distribution.</em> Based on pixel RGB values of sample images, this tool generates color spatial points and conducts clustering and dimension-reduction processing through vector calculation and principal component analysis. The result can help researchers analyze variation in color characteristics of samples from different users.</p><div id=\"Par12\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Extracting tools for sample dominant color tone.</em> Based on the calculation of pixel color features, this tool respectively generates the entire color constitution, by which the dominant 80\u00a0% colors of raw samples can be represented (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig2\">2</a></span>). After that, it will conduct batch processing analysis and generate a form for each sample, manifesting its dominant color tone for following analysis of multi-dimensional color deviation (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig1\">1</a></span>).\n<figure class=\"Figure\" id=\"Fig1\"><div class=\"MediaObject\" id=\"MO1\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig1_HTML.jpg\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig1_HTML.jpg\" alt=\"Fig.\u00a01.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a01.</span> <p class=\"SimplePara\">Extracting tools for sample dominant color (Color figure online)</p> </div></figcaption></figure><figure class=\"Figure\" id=\"Fig2\"><div class=\"MediaObject\" id=\"MO2\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig2_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig2_HTML.gif\" alt=\"Fig.\u00a02.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a02.</span> <p class=\"SimplePara\">Analyzing tools for the similarity of sample dominant colors (themeDistComputingTool_v1).</p> </div></figcaption></figure></div><p id=\"Par13\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Analyzing tools for the similarity of sample dominant color tone.</em> Depending on sample dominant color tone data, this tool calculates the dominant color tone similarity between each pair among 574 samples and generates csv format files as the input of statistical calculations in MDS analysis.</p><p id=\"Par14\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Content Analyzing Technology.</strong> Content analysis is a technology which analyzes the content of samples and generates a structured variable system to describe these samples by means of tags. The tags demonstrate the category and order description of the samples, in order to support future statistical analysis and search for similarity or differences.</p><p id=\"Par15\" class=\"Para\">Base on the overall analysis of samples, several descriptive variables have been proposed and labeled. In the scope of this research, all labels fall into one of the following six categories: picture type, picture theme, composition, means of expression, light and shade, image style.</p><p id=\"Par16\" class=\"Para\">Next, we introduce the notion of matrix of metrical data which is by definition a table for managing samples and corresponding variable labels. All assignment of values to variables results from combination of image feature and artificial labeling. Based on this matrix, all data is imported into SPSS after necessary normalization for next descriptive statistical analysis and advanced calculation.</p><p id=\"Par17\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Statistical Calculation.</strong> Statistical calculation provides a way to discover the internal relation between objective elements shown by pictures and subjective recognition of users, by means of clustering, multi-dimensional analysis and some other tools.</p><p id=\"Par18\" class=\"Para\">Correspondence analysis is the main statistical method used in this research. The connections between variables are represented graphically by interaction summary table. This analysis technique is suitable for situations with many qualitative variables in which connections between these variables of different categories is to be established. SPSS is a prevalent software for this kind of analysis.</p><p id=\"Par19\" class=\"Para\">Nowadays correspondence analysis is widely used in early-stage concept designing, in areas of developing new product, market positioning and advertisement. It has become an important tool for designers and market researchers to solve the problem of evaluating product property, competitor and targeting market.</p></section></div></section><section id=\"Sec5\" tabindex=\"-1\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\"><span class=\"HeadingNumber\">3 </span>Case Study of Photo Sharing Websites</h2><div class=\"content\"><p id=\"Par20\" class=\"Para\">Benefited from massive data mining technology, we selected a popular use case to launch our study which concentrated on constructing user knowledge of photo sharing websites and further analyzing the needs and psychological features of their active users.</p><p id=\"Par21\" class=\"Para\">Many user actions can be regarded as the process of producing user knowledge, including uploading photos and social operations such as clicking a like, commenting and reposting. In this scenario, user knowledge lies in the images, text and user actions. Although text usually indicates the exact thought of users, understanding the meaning by programming is very hard and most importantly text cannot reflect the relation between the image itself and users\u2019 judgement on it.</p><p id=\"Par22\" class=\"Para\">After careful consideration, the popular images in photo-sharing websites were chosen as the main object for studying, fulfilling the purpose of mining information apropos to images itself, user preferences and their relation.</p><section id=\"Sec6\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">3.1 </span>Selecting Target Website</h3><p id=\"Par23\" class=\"Para\">There are many well-known photo-sharing websites including Instagram, Lofter and Flickr by Yahoo. We finally chose Flickr after comparing the foundation date, number of users and some other aspects. Flickr is an image hosting and video hosting website and the web services suite was created by Ludicorp in 2004, acquired by Yahoo in 2005. It offers preeminent services including picture uploading and storing, classification, tagging and searching. Users need to fill in their profiles after registration and the profiles can help us in future study.</p><p id=\"Par24\" class=\"Para\">In the uploading process, users are required to give the picture a title, a description and some tags. For managing photos more effectively, users can create \u201cset\u201d, which is similar to a photo album.</p><div id=\"Par25\" class=\"Para\">Users of Flickr have various background, from professional photographers to PS amateur. All of them enjoy uploading their favorite photos, adding tags and descriptions and creating sets for them. Social operations are even more popular since everybody loves discovering beautiful pictures and grabbing attention of others reflected by the number of like and comments. The feature of a particular user can be revealed by the pictures s/he likes and hottest pictures manifest the inclination of most users. As a result, these hottest pictures provide us an effective way of getting the features we are studying, analyzing user disposition and finally construct user knowledge system of the website. The purpose of this study is exploring the type and features of popular pictures shared by Flickr users and describing their behaviors in Flickr (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig3\">3</a></span>).<figure class=\"Figure\" id=\"Fig3\"><div class=\"MediaObject\" id=\"MO3\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig3_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig3_HTML.gif\" alt=\"Fig.\u00a03.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a03.</span> <p class=\"SimplePara\">Flickr website</p> </div></figcaption></figure></div></section><section id=\"Sec7\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">3.2 </span>Process of Research</h3><p id=\"Par26\" class=\"Para\">Flickr holds an annual show named \u201cbest shot\u201d, selecting the most popular pictures of that year. We selected pictures from \u201c2015 best shot\u201d to narrow down the sample domain. Totally 574 pictures were filtered out through our crawler programs because they receive more than 99 comments or likes.</p><div id=\"Par27\" class=\"Para\">Based on previous state-of-the-art studies, we divided all labels into 6 categories.<div class=\"UnorderedList\"><ul class=\"UnorderedListMarkBullet\"><li> <p id=\"Par28\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Picture type:</strong> daily; documentary; black and white; art; portrait; landscape; abstract; report;</p> </li><li> <p id=\"Par29\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Picture theme:</strong> natural scenery; animals and insects; flowers and plants; still-life objects; character portrait; cultural construction; scene of stories; light rhythm;</p> </li><li> <p id=\"Par30\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Composition:</strong> nine-squared; diagonal; symmetry; frame; guide line; dynamic; triangle; photographic subtraction; special angle; repetition; vertical; curve; slash; centripetal; change; S-shape; open type; balance;</p> </li><li> <p id=\"Par31\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Means of expression:</strong> simplification; choice; comparison; contrast; scenery depth; background; lines; balance; motion; perspective; reflection;</p> </li><li> <p id=\"Par32\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Light and shade:</strong> backlight; soft light; capture light; appropriate exposure; contrast of exposure level; low angle light source; regional exposure; multicolor contrast;</p> </li><li> <p id=\"Par33\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Image style:</strong> traditional nostalgic, romantic, solemn and elegant, deep and solemn, easy dial, decorative arts, comparison of cool &amp; warm, open magic, scarce unique, novel and creative, human sensations, rhythm, non-mainstream</p> </li></ul></div></div><p id=\"Par34\" class=\"Para\">In order to synthesize tag information, the matrix should be transformed into questionnaire. Some experts in both design and photography assigned the tags shown above to the 574 samples based on certain principles explored in previous studies.</p><div id=\"Par35\" class=\"Para\">With the 574 samples and their tags, the matrix of metrical data was established, a measure method previously mentioned. The matrix was being imported to SPSS latter (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig4\">4</a></span>).<figure class=\"Figure\" id=\"Fig4\"><div class=\"MediaObject\" id=\"MO4\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig4_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig4_HTML.gif\" alt=\"Fig.\u00a04.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a04.</span> <p class=\"SimplePara\">Matrix of metrical data</p> </div></figcaption></figure></div></section></div></section><section id=\"Sec8\" tabindex=\"-1\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\"><span class=\"HeadingNumber\">4 </span>Result</h2><div class=\"content\"><section id=\"Sec9\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">4.1 </span>Result Evaluation of Image Feature Identification</h3><p id=\"Par36\" class=\"Para\">According to the design of research previously described, the research of image features mainly involves feature extraction of the samples. The extraction job includes:</p><p id=\"Par37\" class=\"Para\">Make quantitative analysis based on color attributes of the sample (sample pixel RGB value). The main research steps include extracting the dominant color tone. According to the specific features of samples, the composition of the picture usually differs in many ways. Some of them possess a conspicuous dominant color tone while others are composed of many colors. Whatever, the number of dominant color tones of certain sample is able to represent 80\u00a0% of its color information.</p><p id=\"Par38\" class=\"Para\">The representative color tone of samples is evolved from all dominant color tones, which is used to analyze similarity between samples.</p><p id=\"Par39\" class=\"Para\">The distance between the color tones, which occupies relatively larger proportion of dominant color tones, is calculated based on the composition of each sample.</p><div id=\"Par40\" class=\"Para\">Figure\u00a0<span class=\"InternalRef\"><a href=\"#Fig5\">5</a></span> illustrate the similarity of the positioning of color space, based on our calculation and analysis.<figure class=\"Figure\" id=\"Fig5\"><div class=\"MediaObject\" id=\"MO5\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig5_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig5_HTML.gif\" alt=\"Fig.\u00a05.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a05.</span> <p class=\"SimplePara\">The similarity of the positioning of color space. (Color figure online)</p> </div></figcaption></figure></div><div id=\"Par41\" class=\"Para\">Figure\u00a0<span class=\"InternalRef\"><a href=\"#Fig6\">6</a></span> illustrate the similarity analysis of dominant color tones, by the MDS multi-dimensional scaling function of themeDistComputingTool_v1<figure class=\"Figure\" id=\"Fig6\"><div class=\"MediaObject\" id=\"MO6\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig6_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig6_HTML.gif\" alt=\"Fig.\u00a06.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a06.</span> <p class=\"SimplePara\">Theme Color Position-1.</p> </div></figcaption></figure></div><div id=\"Par42\" class=\"Para\">In Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig7\">7</a></span>, it is obvious that all of the samples shows remarkable patterns on positioning distribution of dominant color tone similarity. Based on the distribution of scattered plots, a two element regression equation is obtained by two order curve fitting:<figure class=\"Figure\" id=\"Fig7\"><div class=\"MediaObject\" id=\"MO7\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig7_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig7_HTML.gif\" alt=\"Fig.\u00a07.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a07.</span> <p class=\"SimplePara\">Theme Color Position-2 (Color figure online)</p> </div></figcaption></figure></div><div id=\"Par43\" class=\"Para\"> <div id=\"Equa\" class=\"Equation EquationMathjax\"><div class=\"EquationContent\">$$ {\\text{y}} = - 0. 2 + - 0. 2 7*{\\text{x}} + 0. 5 3*{\\text{x}}^{ 2} $$</div></div> </div><div id=\"Par44\" class=\"Para\">To make the distribution pattern of the result more easily determined, researchers supplement information for Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig8\">8</a></span> and 574 dominant color tone palette which are also positioned to the corresponding scattered positions.<figure class=\"Figure\" id=\"Fig8\"><div class=\"MediaObject\" id=\"MO9\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig8_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig8_HTML.gif\" alt=\"Fig.\u00a08.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a08.</span> <p class=\"SimplePara\">Picture theme</p> </div></figcaption></figure></div><p id=\"Par45\" class=\"Para\">We found that despite the differences in properties and content among the 574 samples, a significant pattern exists in the features of visual cognition of dominant color tones. The pattern was represented by the mild gradient of brightness from darkness on the left to brightness on the right. However, no obvious pattern was recognized in vertical dimension. In addition, the significance of saturation in center and center-right areas in the U-shape curve area is higher than that in other areas.</p><p id=\"Par46\" class=\"Para\">To sum up, it is convincing that the 574 samples primarily reflects differences in saturation and color temperature in terms of color properties, based on the result of color space positioning analysis and dominant color tone similarity MDS analysis.</p></section><section id=\"Sec10\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">4.2 </span>Result Evaluation of Statistical Calculation</h3><p id=\"Par47\" class=\"Para\">Recall previous discussion, correspondence analysis is the main method in this research. The location map analysis, resulting from 574 samples in all dimensions, is discussed below. Among all the dimensions, abundance of color tones is particular interesting so that the first part of this section makes a comparison between it and other dimensions while the second part discusses results within the other dimensions.</p><p id=\"Par48\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Abundance of Color Tones Compare to Other Dimensions</strong> </p><p id=\"Par49\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Picture Theme.</em> Picture Theme The sig value is 1.000a, which indicates that there\u2019s no significant relation between picture theme and tone abundance. No typical pattern is recognized in the distribution of the sample from different topics. In addition, the theme of still life objects is rare in the sample.</p><div id=\"Par50\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Composition.</em> The sig value is 1.000a, one can see that most types of the composition is in a relatively concentrated manner while the diagonal type and curves type are relatively rare (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig9\">9</a></span>).<figure class=\"Figure\" id=\"Fig9\"><div class=\"MediaObject\" id=\"MO10\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig9_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig9_HTML.gif\" alt=\"Fig.\u00a09.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a09.</span> <p class=\"SimplePara\">Composition</p> </div></figcaption></figure></div><div id=\"Par51\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Means of Expression.</em> In this figure, excepting the line type, the performance is similar in the majority of the sample (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig10\">10</a></span>).<figure class=\"Figure\" id=\"Fig10\"><div class=\"MediaObject\" id=\"MO11\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig10_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig10_HTML.gif\" alt=\"Fig.\u00a010.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a010.</span> <p class=\"SimplePara\">Means of expression</p> </div></figcaption></figure></div><div id=\"Par52\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Light and Shade.</em> The sig value is 1.000a. There is no obvious correlation between lighting and tone abundance in this dimension. Meanwhile, low angle light source is more unique due to the special angle (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig11\">11</a></span>).<figure class=\"Figure\" id=\"Fig11\"><div class=\"MediaObject\" id=\"MO12\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig11_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig11_HTML.gif\" alt=\"Fig.\u00a011.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a011.</span> <p class=\"SimplePara\">Lights and shade</p> </div></figcaption></figure></div><div id=\"Par53\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Image Style.</em> The sig value is 1.000a. Image style and tone abundance have no significant correlation. However, the rhythm is relatively rare (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig12\">12</a></span>).<figure class=\"Figure\" id=\"Fig12\"><div class=\"MediaObject\" id=\"MO13\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig12_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig12_HTML.gif\" alt=\"Fig.\u00a012.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a012.</span> <p class=\"SimplePara\">Image style</p> </div></figcaption></figure></div><p id=\"Par54\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Results Within Other Dimensions.</strong> Overall, three common features were found through all 574 samples. Firstly, in terms of the type, pictures about scenery or daily lives ranked the highest; then follows art, documentary and portrait; report and abstract had the least quantity. Secondly, for the composition, most samples were showed in a way of nine-squared or symmetry, which is associated with human aesthetic physiological characteristics. People like pictures which are concisely composed with a certain guidance or restriction, such as radial line, leading line, diagonal, or frame. The third common feature lies in image style. The most popular pictures are usually unique and relaxing. Nostalgic, romantic, solemn, aesthetic and novel ingredients are welcome as well. In contrast, popular pictures are scarcely in themes of rhythm, contrast or humanity.</p><p id=\"Par55\" class=\"Para\">The four results of specific analysis are shown in following figures.</p><p id=\"Par56\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Picture Type Compare to Image Style.</em> The correspondence analysis of picture type and styles, with 574 effective samples and Sig value zero, indicating that there is a significant correlation between the type and the style.</p><div id=\"Par57\" class=\"Para\">The common aesthetic taste of inclining scenery and daily type of pictures was very likely being developed along with the evolution of human beings. Analysis of this type indicates that ancient prairie scenery, composed by fresh grass, low jungles and winding streams, gives comfortable and congruent feelings to people living in nearly all places. People often find senses of identity from documentary and portrait paintings, making it the second popular type. Abstract pictures are only appreciated by a small group of people (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig13\">13</a></span>).<figure class=\"Figure\" id=\"Fig13\"><div class=\"MediaObject\" id=\"MO14\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig13_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig13_HTML.gif\" alt=\"Fig.\u00a013.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a013.</span> <p class=\"SimplePara\">Picture type&amp;Image style</p> </div></figcaption></figure></div><p id=\"Par58\" class=\"Para\">The result also shows that there\u2019s a common mapping between image content type and means of expression. Sceneries are normally expressed through romantic, solemn, elegant or temperature contrasting styles, portraits by nostalgic and black-white ways and artistic pictures by decorating, novel, open magical ones.</p><div id=\"Par59\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Composition Compare to Image Style.</em> In the correspondence analysis of this comparison, 562 effective samples leaded to a sig value of 0.005, suggesting a significant connection between image style and composition (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig14\">14</a></span>).<figure class=\"Figure\" id=\"Fig14\"><div class=\"MediaObject\" id=\"MO15\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig14_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig14_HTML.gif\" alt=\"Fig.\u00a014.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a014.</span> <p class=\"SimplePara\">Composition&amp;Image style</p> </div></figcaption></figure></div><p id=\"Par60\" class=\"Para\">In the history of human aesthetic, nine-squared and symmetric have occupied their place in composition. Famous historical buildings, from Gothic to Chinese style, are designed to be strictly symmetric. Centripetal, guide-line, diagonal and frame are also prevailing metamorphism of symmetric.</p><p id=\"Par61\" class=\"Para\">The paring of romantic with symmetric, traditional with vertical, nine-squared with temperature contrast, can serve as a good reference for future composition designing.</p><div id=\"Par62\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Light and Shade Compare to Image Style.</em> Scarce unique and easy dial are the two most welcome styles. The pessimistic nature of deep and solemn and the direct definition of non-mainstream causes the lack of attraction to the majority (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig15\">15</a></span>).<figure class=\"Figure\" id=\"Fig15\"><div class=\"MediaObject\" id=\"MO16\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig15_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig15_HTML.gif\" alt=\"Fig.15.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.15.</span> <p class=\"SimplePara\">Light and shade&amp;Image style</p> </div></figcaption></figure></div><p id=\"Par63\" class=\"Para\">Considering both dimensions, there\u2019s significant relation between backlight and solemn, capture light and temperature contrast, regional exposure and elegant. Appropriate exposure is suitable for many styles, including romantic, human sensations, traditional nostalgic and easy dial.</p><div id=\"Par64\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Composition Compare to Light and Shade.</em> Soft light pictures typically adopt expressions of S-shape, triangle, open type and centripetal. Diagonal and guide-lines are mostly used in photographic subtraction, while appropriate exposure in balance. Soft light and contrast of exposure level are totally opposite shown in the figure, indicating the thorough difference (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig16\">16</a></span>).<figure class=\"Figure\" id=\"Fig16\"><div class=\"MediaObject\" id=\"MO17\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig16_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig16_HTML.gif\" alt=\"Fig.\u00a016.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a016.</span> <p class=\"SimplePara\">Composition&amp;Light and shade</p> </div></figcaption></figure></div></section></div></section><section id=\"Sec11\" tabindex=\"-1\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\"><span class=\"HeadingNumber\">5 </span>Conclusion</h2><div class=\"content\"><p id=\"Par65\" class=\"Para\">By extracting features of the sample images, analyzing the contents of semantic tags, looking for common features in popular images which hold relatively high degree of users\u2019 attention, and studying the corresponding relationship between each label; this essay tends to figure out why users are paying more attention to landscape images. In addition, users favor composition balance, nine-squared format, with proper exposure, backlight or the way of capturing light. Besides, users also prefer the traditional nostalgia, deep dignified black and white photos or portraits; Photos they like range from lyrical romantic, lively, unique landscape to the daily theme; Over and above, users are also interested in innovative photos as well as open magic art photos.</p><p id=\"Par66\" class=\"Para\">These findings are significant for the construction of photo sharing site user knowledge. In the future, against such users who like sharing photos on these photos sharing websites, you can understand the relationship between the key themes of their favorite pictures, the composition and expression, light and shadow, style and tone. Designers can learn the preferences and needs of such users through first-hand detailed and reliable data to apply to other designs designed for this kind of user.</p><p id=\"Par67\" class=\"Para\">In this study, the method used is construction of user knowledge system by analyzing user behavior among those who like sharing pictures. This method can also be used in many other aspects of the behavior of keywords. For example, in the field of advertising communication, product packing design and all other users knowledge mining areas related to pictures.</p><p id=\"Par68\" class=\"Para\">In this study, the construction of the user knowledge mining method is different from the traditional method of user experience. As a result, it can be used in many aspects and fields to establish the user knowledge system based on general characteristics of different users\u2019 needs, concerns, and thus facilitating designers\u2019 working process. When identified certain feature of the keyword behavior of the user, designer can quickly draw from the user knowledge bank to find effective and usable research data for reference to aid their design decisions.</p><p id=\"Par69\" class=\"Para\">Mining and Construction of such a user\u2019s knowledge system can be time-consuming in the early stage. However, once the user knowledge bank has been set up, it will not only facilitate the designer to effectively understand the needs of users and help decision-making, but also makes it easier for multiple designers in one single design projects to understand the common goal. In this way, the design consistency among several designers can be ensured and it saves designers time in reducing communication costs and in the end largely improves the communication quality.</p><p id=\"Par70\" class=\"Para\">This study mainly introduces the user knowledge, image mining method. What remains to be analyzed is the construction of other points of the user knowledge, such as text and sound. It is an area which still worth further studying and forms general research methods and theories. These aspects can be used as subsequent supplementary research for user\u2019s knowledge system construction.</p><p id=\"Par71\" class=\"Para\">A well-established user database is built on both the traditional method and the innovative new one. Getting to understand users\u2019 need from multi-dimensional perspective of big data method as well as the traditional way of conducting interview, survey and focus group seems to be the new trend. However, this essay deems that the new method of construction is fundamental to this trend while combined with the traditional method will make it better.</p></div></section></div><section class=\"Section1 RenderAsSection1\" id=\"Bib1\" tabindex=\"-1\"><h2 class=\"Heading\">References</h2><div class=\"content\"><ol class=\"BibliographyWrapper\"><li class=\"Citation\"><div class=\"CitationNumber\">1.</div><div class=\"CitationContent\" id=\"CR1\">McDonald, J.E., Schvaneveldt, R.W.: The application of user knowledge to interface design. In: Cognitive Science and its Applications for Human-Computer Interaction, pp. 289\u2013338 (1988)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=McDonald%2C%20J.E.%2C%20Schvaneveldt%2C%20R.W.%3A%20The%20application%20of%20user%20knowledge%20to%20interface%20design.%20In%3A%20Cognitive%20Science%20and%20its%20Applications%20for%20Human-Computer%20Interaction%2C%20pp.%20289%E2%80%93338%20%281988%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">2.</div><div class=\"CitationContent\" id=\"CR2\">Blandford, A., Young, R.M.: Specifying user knowledge for the design of interactive systems. Softw. Eng. J. <strong class=\"EmphasisTypeBold \">11</strong>(6), 323\u2013333 (1996)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1049/sej.1996.0043\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Specifying%20user%20knowledge%20for%20the%20design%20of%20interactive%20systems&amp;author=A.%20Blandford&amp;author=RM.%20Young&amp;journal=Softw.%20Eng.%20J.&amp;volume=11&amp;issue=6&amp;pages=323-333&amp;publication_year=1996\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">3.</div><div class=\"CitationContent\" id=\"CR3\">De Rosis, F., Pizzutilo, S., Russo, A., et al.: Modeling the user knowledge by belief networks. User Model. User-Adap. Inter. <strong class=\"EmphasisTypeBold \">2</strong>(4), 367\u2013388 (1992)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1007/BF01101110\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Modeling%20the%20user%20knowledge%20by%20belief%20networks&amp;author=F.%20Rosis&amp;author=S.%20Pizzutilo&amp;author=A.%20Russo&amp;journal=User%20Model.%20User-Adap.%20Inter.&amp;volume=2&amp;issue=4&amp;pages=367-388&amp;publication_year=1992\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">4.</div><div class=\"CitationContent\" id=\"CR4\">Tesch, D., Sobol, M.G., Klein, G., et al.: User and developer common knowledge: Effect on the success of information system development projects. Int. J. Project Manage. <strong class=\"EmphasisTypeBold \">27</strong>(7), 657\u2013664 (2009)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1016/j.ijproman.2009.01.002\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=User%20and%20developer%20common%20knowledge%3A%20Effect%20on%20the%20success%20of%20information%20system%20development%20projects&amp;author=D.%20Tesch&amp;author=MG.%20Sobol&amp;author=G.%20Klein&amp;journal=Int.%20J.%20Project%20Manage.&amp;volume=27&amp;issue=7&amp;pages=657-664&amp;publication_year=2009\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">5.</div><div class=\"CitationContent\" id=\"CR5\">Bevan, N.: What is the difference between the purpose of usability and user experience evaluation methods. In: Proceedings of the Workshop UXEM, 9, pp. 1\u20134 (2009)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Bevan%2C%20N.%3A%20What%20is%20the%20difference%20between%20the%20purpose%20of%20usability%20and%20user%20experience%20evaluation%20methods.%20In%3A%20Proceedings%20of%20the%20Workshop%20UXEM%2C%209%2C%20pp.%201%E2%80%934%20%282009%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">6.</div><div class=\"CitationContent\" id=\"CR6\">Vermeeren, A.P.O.S., Law, E.L.C., Roto, V., et al.: User experience evaluation methods: current state and development needs. In: Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries, pp. 521\u2013530. ACM (2010)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Vermeeren%2C%20A.P.O.S.%2C%20Law%2C%20E.L.C.%2C%20Roto%2C%20V.%2C%20et%20al.%3A%20User%20experience%20evaluation%20methods%3A%20current%20state%20and%20development%20needs.%20In%3A%20Proceedings%20of%20the%206th%20Nordic%20Conference%20on%20Human-Computer%20Interaction%3A%20Extending%20Boundaries%2C%20pp.%20521%E2%80%93530.%20ACM%20%282010%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">7.</div><div class=\"CitationContent\" id=\"CR7\">Law, E.L.C., Roto, V., Hassenzahl, M., et al.: Understanding, scoping and defining user experience: a survey approach. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 719\u2013728. ACM (2009)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Law%2C%20E.L.C.%2C%20Roto%2C%20V.%2C%20Hassenzahl%2C%20M.%2C%20et%20al.%3A%20Understanding%2C%20scoping%20and%20defining%20user%20experience%3A%20a%20survey%20approach.%20In%3A%20Proceedings%20of%20the%20SIGCHI%20Conference%20on%20Human%20Factors%20in%20Computing%20Systems%2C%20pp.%20719%E2%80%93728.%20ACM%20%282009%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">8.</div><div class=\"CitationContent\" id=\"CR8\">Hassenzahl, M., Tractinsky, N.: User experience-a research agenda[J]. Behav. Inf. Technol. <strong class=\"EmphasisTypeBold \">25</strong>(2), 91\u201397 (2006)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1080/01449290500330331\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=User%20experience-a%20research%20agenda%5BJ%5D&amp;author=M.%20Hassenzahl&amp;author=N.%20Tractinsky&amp;journal=Behav.%20Inf.%20Technol.&amp;volume=25&amp;issue=2&amp;pages=91-97&amp;publication_year=2006\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">9.</div><div class=\"CitationContent\" id=\"CR9\">V\u00e4\u00e4n\u00e4nen-Vainio-Mattila, K., Roto, V., Hassenzahl, M.: Towards practical user experience evaluation methods. In: Law, E.L.-C., Bevan, N., Christou, G., Springett, M., L\u00e1rusd\u00f3ttir, M. (eds.) Meaningful Measures: Valid Useful User Experience Measurement, pp. 19\u201322 (2008)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=V%C3%A4%C3%A4n%C3%A4nen-Vainio-Mattila%2C%20K.%2C%20Roto%2C%20V.%2C%20Hassenzahl%2C%20M.%3A%20Towards%20practical%20user%20experience%20evaluation%20methods.%20In%3A%20Law%2C%20E.L.-C.%2C%20Bevan%2C%20N.%2C%20Christou%2C%20G.%2C%20Springett%2C%20M.%2C%20L%C3%A1rusd%C3%B3ttir%2C%20M.%20%28eds.%29%20Meaningful%20Measures%3A%20Valid%20Useful%20User%20Experience%20Measurement%2C%20pp.%2019%E2%80%9322%20%282008%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">10.</div><div class=\"CitationContent\" id=\"CR10\">Obrist, M., Roto, V., V\u00e4\u00e4n\u00e4nen-Vainio-Mattila, K.: User experience evaluation: do you know which method to use? In: CHI 2009 Extended Abstracts on Human Factors in Computing Systems, pp. 2763\u20132766. ACM (2009)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Obrist%2C%20M.%2C%20Roto%2C%20V.%2C%20V%C3%A4%C3%A4n%C3%A4nen-Vainio-Mattila%2C%20K.%3A%20User%20experience%20evaluation%3A%20do%20you%20know%20which%20method%20to%20use%3F%20In%3A%20CHI%202009%20Extended%20Abstracts%20on%20Human%20Factors%20in%20Computing%20Systems%2C%20pp.%202763%E2%80%932766.%20ACM%20%282009%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">11.</div><div class=\"CitationContent\" id=\"CR11\">Maguire, M.: Methods to support human-centred design. Int. J. Hum. Comput. Stud. <strong class=\"EmphasisTypeBold \">55</strong>(4), 587\u2013634 (2001)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1006/ijhc.2001.0503\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceZLBID\"><a class=\"gtm-reference\" data-reference-type=\"MATH\" target=\"_blank\" rel=\"noopener\" href=\"http://www.emis.de/MATH-item?0984.68616\"><span><span>zbMATH</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Methods%20to%20support%20human-centred%20design&amp;author=M.%20Maguire&amp;journal=Int.%20J.%20Hum.%20Comput.%20Stud.&amp;volume=55&amp;issue=4&amp;pages=587-634&amp;publication_year=2001\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">12.</div><div class=\"CitationContent\" id=\"CR12\">Fan, W., Bifet, A.: Mining big data: current status, and forecast to the future. ACM sIGKDD Explor. Newsl. <strong class=\"EmphasisTypeBold \">14</strong>(2), 1\u20135 (2013)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1145/2481244.2481246\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Mining%20big%20data%3A%20current%20status%2C%20and%20forecast%20to%20the%20future&amp;author=W.%20Fan&amp;author=A.%20Bifet&amp;journal=ACM%20sIGKDD%20Explor.%20Newsl.&amp;volume=14&amp;issue=2&amp;pages=1-5&amp;publication_year=2013\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">13.</div><div class=\"CitationContent\" id=\"CR13\">Fisher, D., DeLine, R., Czerwinski, M., et al.: Interactions with big data analytics. Interactions <strong class=\"EmphasisTypeBold \">19</strong>(3), 50\u201359 (2012)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1145/2168931.2168943\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Interactions%20with%20big%20data%20analytics&amp;author=D.%20Fisher&amp;author=R.%20DeLine&amp;author=M.%20Czerwinski&amp;journal=Interactions&amp;volume=19&amp;issue=3&amp;pages=50-59&amp;publication_year=2012\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">14.</div><div class=\"CitationContent\" id=\"CR14\">Sarmento, L., Carvalho, P., Silva, M.J., et al.: Automatic creation of a reference corpus for political opinion mining in user-generated content. In: Proceedings of the 1st International CIKM Workshop on Topic-Sentiment Analysis for Mass Opinion, pp. 29\u201336. ACM (2009)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Sarmento%2C%20L.%2C%20Carvalho%2C%20P.%2C%20Silva%2C%20M.J.%2C%20et%20al.%3A%20Automatic%20creation%20of%20a%20reference%20corpus%20for%20political%20opinion%20mining%20in%20user-generated%20content.%20In%3A%20Proceedings%20of%20the%201st%20International%20CIKM%20Workshop%20on%20Topic-Sentiment%20Analysis%20for%20Mass%20Opinion%2C%20pp.%2029%E2%80%9336.%20ACM%20%282009%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">15.</div><div class=\"CitationContent\" id=\"CR15\">Graham, J.: Flickr of idea on a gaming project led to photo website. USA Today, 27 (2006)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Graham%2C%20J.%3A%20Flickr%20of%20idea%20on%20a%20gaming%20project%20led%20to%20photo%20website.%20USA%20Today%2C%2027%20%282006%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">16.</div><div class=\"CitationContent\" id=\"CR16\">Miller, A.D., Edwards, W.K.: Give and take: a study of consumer photo-sharing culture and practice. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 347\u2013356. ACM (2007)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Miller%2C%20A.D.%2C%20Edwards%2C%20W.K.%3A%20Give%20and%20take%3A%20a%20study%20of%20consumer%20photo-sharing%20culture%20and%20practice.%20In%3A%20Proceedings%20of%20the%20SIGCHI%20Conference%20on%20Human%20Factors%20in%20Computing%20Systems%2C%20pp.%20347%E2%80%93356.%20ACM%20%282007%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">17.</div><div class=\"CitationContent\" id=\"CR17\">Liu, S.B., Palen, L., Sutton, J., et al.: In search of the bigger picture: The emergent role of on-line photo sharing in times of disaster. In: Proceedings of the Information Systems for Crisis Response and Management Conference (ISCRAM) (2008)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Liu%2C%20S.B.%2C%20Palen%2C%20L.%2C%20Sutton%2C%20J.%2C%20et%20al.%3A%20In%20search%20of%20the%20bigger%20picture%3A%20The%20emergent%20role%20of%20on-line%20photo%20sharing%20in%20times%20of%20disaster.%20In%3A%20Proceedings%20of%20the%20Information%20Systems%20for%20Crisis%20Response%20and%20Management%20Conference%20%28ISCRAM%29%20%282008%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">18.</div><div class=\"CitationContent\" id=\"CR18\">Sigurbj\u00f6rnsson, B., Van Zwol, R.: Flickr tag recommendation based on collective knowledge. In: Proceedings of the 17th International Conference on World Wide Web, pp. 327\u2013336. ACM (2008)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Sigurbj%C3%B6rnsson%2C%20B.%2C%20Van%20Zwol%2C%20R.%3A%20Flickr%20tag%20recommendation%20based%20on%20collective%20knowledge.%20In%3A%20Proceedings%20of%20the%2017th%20International%20Conference%20on%20World%20Wide%20Web%2C%20pp.%20327%E2%80%93336.%20ACM%20%282008%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">19.</div><div class=\"CitationContent\" id=\"CR19\">Mislove, A., Koppula, H.S., Gummadi, K.P., et al.: Growth of the flickr social network. In: Proceedings of the First Workshop on Online Social Networks, pp. 25\u201330. ACM (2008)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Mislove%2C%20A.%2C%20Koppula%2C%20H.S.%2C%20Gummadi%2C%20K.P.%2C%20et%20al.%3A%20Growth%20of%20the%20flickr%20social%20network.%20In%3A%20Proceedings%20of%20the%20First%20Workshop%20on%20Online%20Social%20Networks%2C%20pp.%2025%E2%80%9330.%20ACM%20%282008%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">20.</div><div class=\"CitationContent\" id=\"CR20\">Kennedy, L., Naaman, M., Ahern, S., et al.: How flickr helps us make sense of the world: context and content in community-contributed media collections. In: Proceedings of the 15th International Conference on Multimedia, pp. 631\u2013640. ACM (2007)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Kennedy%2C%20L.%2C%20Naaman%2C%20M.%2C%20Ahern%2C%20S.%2C%20et%20al.%3A%20How%20flickr%20helps%20us%20make%20sense%20of%20the%20world%3A%20context%20and%20content%20in%20community-contributed%20media%20collections.%20In%3A%20Proceedings%20of%20the%2015th%20International%20Conference%20on%20Multimedia%2C%20pp.%20631%E2%80%93640.%20ACM%20%282007%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">21.</div><div class=\"CitationContent\" id=\"CR21\">Yongchang, J.: Knowledge architecture based on user experience: a review of the basic principles for knowledge architecture in web 2.0. J. China Soc. Sci. Techn. Inf. <strong class=\"EmphasisTypeBold \">5</strong>, 018 (2010)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Knowledge%20architecture%20based%20on%20user%20experience%3A%20a%20review%20of%20the%20basic%20principles%20for%20knowledge%20architecture%20in%20web%202.0&amp;author=J.%20Yongchang&amp;journal=J.%20China%20Soc.%20Sci.%20Techn.%20Inf.&amp;volume=5&amp;pages=018&amp;publication_year=2010\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">22.</div><div class=\"CitationContent\" id=\"CR22\">McGinn, J., Kotamraju, N.: Datadriven persona development. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 1521\u20131524.\u00a0ACM\u00a0(2008)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=McGinn%2C%20J.%2C%20Kotamraju%2C%20N.%3A%20Datadriven%20persona%20development.%20In%3A%20Proceedings%20of%20the%20SIGCHI%20Conference%20on%20Human%20Factors%20in%20Computing%20Systems%2C%20pp.%201521%E2%80%931524.%C2%A0ACM%C2%A0%282008%29\"><span><span>Google Scholar</span></span></a></span></span></div></li></ol></div></section><section class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\" id=\"copyrightInformation\">Copyright information</h2><div class=\"ArticleCopyright content\"><div class=\"ChapterCopyright\">\u00a9\u00a0Springer International Publishing Switzerland\u00a02016</div></div></section><section id=\"authorsandaffiliations\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\">Authors and Affiliations</h2><div class=\"content authors-affiliations u-interface\"><ul class=\"test-contributor-names\"><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors-affiliations__name\">Nan\u00a0Liang</span><ul class=\"authors-affiliations__indexes u-inline-list\" data-role=\"AuthorsIndexes\"><li data-affiliation=\"affiliation-1\">1</li></ul></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors-affiliations__name\">Jiaming\u00a0Zhong</span><ul class=\"authors-affiliations__indexes u-inline-list\" data-role=\"AuthorsIndexes\"><li data-affiliation=\"affiliation-1\">1</li></ul></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors-affiliations__name\">Di\u00a0Wang</span><ul class=\"authors-affiliations__indexes u-inline-list\" data-role=\"AuthorsIndexes\"><li data-affiliation=\"affiliation-1\">1</li></ul></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors-affiliations__name\">Liqun\u00a0Zhang</span><ul class=\"authors-affiliations__indexes u-inline-list\" data-role=\"AuthorsIndexes\"><li data-affiliation=\"affiliation-1\">1</li></ul><span class=\"author-information\"><span class=\"author-information__contact u-icon-before\"><a href=\"mailto:zhanglq@sjtu.edu.cn\" title=\"zhanglq@sjtu.edu.cn\" itemprop=\"email\" data-track=\"click\" data-track-action=\"Email author\" data-track-label=\"\">Email author</a></span></span></li></ul><ol class=\"test-affiliations\"><li class=\"affiliation\" data-test=\"affiliation-1\" data-affiliation-highlight=\"affiliation-1\" itemscope=\"\" itemtype=\"http://schema.org/Organization\"><span class=\"affiliation__count\">1.</span><span class=\"affiliation__item\"><span itemprop=\"department\" class=\"affiliation__department\">Institute of Design Management</span><span itemprop=\"name\" class=\"affiliation__name\">S.J.T.U.</span><span itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/PostalAddress\" class=\"affiliation__address\"><span itemprop=\"addressRegion\" class=\"affiliation__city\">Shanghai</span><span itemprop=\"addressCountry\" class=\"affiliation__country\">China</span></span></span></li></ol></div></section></div>\n                        </article>\n                        <aside class=\"section section--collapsible\" id=\"AboutThisContent\">\n    <h2 class=\"section__heading\" id=\"aboutcontent\">About this paper</h2>\n    <div class=\"section__content bibliographic-information\">\n        \n        <div class=\"crossmark__adjacent\">\n            <dl class=\"citation-info u-highlight-target u-mb-16\" id=\"citeas\" tabindex=\"-1\">\n    <dt class=\"test-cite-heading\">\n        Cite this paper as:\n    </dt>\n    <dd id=\"citethis-text\">Liang N., Zhong J., Wang D., Zhang L. (2016) The Exploration of User Knowledge Architecture Based on Mining User Generated Contents \u2013 An Application Case of Photo-Sharing Website. In: Marcus A. (eds) Design, User Experience, and Usability: Technological Contexts. DUXU 2016. Lecture Notes in Computer Science, vol 9748. Springer, Cham. https://doi.org/10.1007/978-3-319-40406-6_17</dd>\n</dl>\n                <ul class=\"bibliographic-information__list bibliographic-information__list--inline\">\n        <li class=\"bibliographic-information__item\">\n            <span class=\"bibliographic-information__title\">First Online</span>\n            <span class=\"bibliographic-information__value u-overflow-wrap\">22 June 2016</span>\n        </li>\n        <li class=\"bibliographic-information__item\">\n            <span class=\"bibliographic-information__title\">DOI</span>\n            <span class=\"bibliographic-information__value u-overflow-wrap\" id=\"doi-url\">https://doi.org/10.1007/978-3-319-40406-6_17</span>\n        </li>\n            <li class=\"bibliographic-information__item\">\n                <span class=\"bibliographic-information__title\">Publisher Name</span>\n                <span class=\"bibliographic-information__value\" id=\"publisher-name\">Springer, Cham</span>\n            </li>\n            <li class=\"bibliographic-information__item\">\n                <span class=\"bibliographic-information__title\">Print ISBN</span>\n                <span class=\"bibliographic-information__value\" id=\"print-isbn\">978-3-319-40405-9</span>\n            </li>\n            <li class=\"bibliographic-information__item\">\n                <span class=\"bibliographic-information__title\">Online ISBN</span>\n                <span class=\"bibliographic-information__value\" id=\"electronic-isbn\">978-3-319-40406-6</span>\n            </li>\n\n                <li class=\"bibliographic-information__item\">\n            <span class=\"bibliographic-information__title\">eBook Packages</span>\n                <span class=\"bibliographic-information__value\" itemprop=\"genre\"><a id=\"ebook-package\" href=\"/search?facet-content-type&#x3D;%22Book%22&amp;package&#x3D;11645&amp;facet-start-year&#x3D;2016&amp;facet-end-year&#x3D;2016\">Computer Science</a></span>\n                <span class=\"bibliographic-information__value\" itemprop=\"genre\"><a id=\"ebook-package\" href=\"/search?facet-content-type&#x3D;%22Book%22&amp;package&#x3D;43710&amp;facet-start-year&#x3D;2016&amp;facet-end-year&#x3D;2016\">Computer Science (R0)</a></span>\n        </li>\n\n    </ul>\n\n            <ul class=\"bibliographic-information__list\">\n        <li class=\"bibliographic-information__item\">\n            <a id=\"reprintsandpermissions-link\" target=\"_blank\" rel=\"noopener\" href=\"https://s100.copyright.com/AppDispatchServlet?publisherName&#x3D;SpringerNature&amp;orderBeanReset&#x3D;true&amp;orderSource&#x3D;SpringerLink&amp;copyright&#x3D;Springer+International+Publishing+Switzerland&amp;author&#x3D;Nan+Liang%2C+Jiaming+Zhong%2C+Di+Wang+et+al&amp;contentID&#x3D;10.1007%2F978-3-319-40406-6_17&amp;endPage&#x3D;192&amp;publicationDate&#x3D;2016&amp;startPage&#x3D;180&amp;publication&#x3D;eBook&amp;title&#x3D;The+Exploration+of+User+Knowledge+Architecture+Based+on+Mining+User+Generated+Contents+%E2%80%93+An+Application+Case+of+Photo-Sharing+Website&amp;imprint&#x3D;Springer+International+Publishing+Switzerland\" title=\"Visit RightsLink for information about reusing this paper\" data-track=\"click\" data-track-action=\"Reprints and Permissions\" data-track-label=\"\">Reprints and Permissions</a>\n        </li>\n</ul>\n\n\n\n        </div>\n      \n      \n          \n    </div>\n</aside>\n\n                        <div class=\"section section--collapsible uptodate-recommendations gtm-recommendations\">\n    <h2 class=\"uptodate-recommendations__title section__heading gtm-recommendations__title\" id=\"uptodaterecommendations\">Personalised recommendations</h2>\n    <div class=\"section__content\">\n        <div class=\"uptodate-recommendations__container\">\n             <link rel=\"uptodate-inline\" href=\"/springerlink-static/1923692707/css/recommendations.css\"/>\n        </div>\n    </div>\n</div>\n                                <div id=\"doubleclick-native-ad\" data-google-ad=\"native\"></div>\n\n                        \n\n\n                <div class=\"sticky-banner sticky-banner--no-download  u-interface u-hide\" data-component=\"SpringerLink.StickyBanner\" data-namespace=\"hasButton\">\n                    <div class=\"sticky-banner__container\">\n                            <div class=\"citations\" data-component=\"SV.Dropdown\" data-namespace=\"citationsSticky\">\n        <h3 class=\"u-h4\" data-role=\"button-dropdown__title\">\n    <span>Cite</span>\n    <span class=\"hide-text-small\">paper</span>\n</h3>\n<ul class=\"citations__content\" data-role=\"button-dropdown__content\">\n    <li>\n        <a href=\"#citeas\" data-track=\"click\" data-track-action=\"Cite as link\" data-track-label=\"Cite dropdown\">How to cite?</a>\n    </li>\n        <li>\n            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;refman&amp;flavour&#x3D;citation\"\n               title=\"Download this paper&#39;s citation as a .RIS file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"RIS\">\n                <span class=\"citations__extension\" data-gtmlabel=\"RIS\">\n                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>\n                    .RIS\n                </span>\n                <span class=\"citations__types\">\n                        <span>\n                            Papers\n                        </span>\n                        <span>\n                            Reference Manager\n                        </span>\n                        <span>\n                            RefWorks\n                        </span>\n                        <span>\n                            Zotero\n                        </span>\n                </span>\n            </a>\n        </li>\n        <li>\n            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;endnote&amp;flavour&#x3D;citation\"\n               title=\"Download this paper&#39;s citation as a .ENW file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"ENW\">\n                <span class=\"citations__extension\" data-gtmlabel=\"ENW\">\n                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>\n                    .ENW\n                </span>\n                <span class=\"citations__types\">\n                        <span>\n                            EndNote\n                        </span>\n                </span>\n            </a>\n        </li>\n        <li>\n            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;bibtex&amp;flavour&#x3D;citation\"\n               title=\"Download this paper&#39;s citation as a .BIB file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"BIB\">\n                <span class=\"citations__extension\" data-gtmlabel=\"BIB\">\n                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>\n                    .BIB\n                </span>\n                <span class=\"citations__types\">\n                        <span>\n                            BibTeX\n                        </span>\n                        <span>\n                            JabRef\n                        </span>\n                        <span>\n                            Mendeley\n                        </span>\n                </span>\n            </a>\n        </li>\n</ul>\n    </div>\n\n                                <div>\n        <a class=\"c-button share-this test-shareby-sharelink-link\" data-test=\"shareable-link\" target=\"_blank\" rel=\"noopener\" href=\"/sharelink/10.1007/978-3-319-40406-6_17\" data-track=\"click\" data-track-action=\"Share via\" data-track-label=\"ShareLink\">\n            <span>Share</span>\n            <span class=\"hide-text-small\">paper</span>\n        </a>\n    </div>\n\n\n\n\n                    </div>\n                </div>\n\n\n\n                    </div>\n                    <aside class=\"main-sidebar-right u-interface\">\n                        <div data-role=\"sticky-wrapper\">\n                            <div class=\"main-sidebar-right__content u-composite-layer\" data-component=\"SpringerLink.StickySidebar\">\n                                <div class=\"article-actions\" id=\"article-actions\">\n                                    <h2 class=\"u-screenreader-only\" aria-hidden=\"true\">Actions</h2>\n\n\n                                    <div class=\"u-js-hide u-js-show-two-col\">\n                                        \n        \n\n\n\n\n                                            <div class=\"citations\" data-component=\"SV.Dropdown\" data-namespace=\"citations\">\n        <h3 class=\"u-h4\" data-role=\"button-dropdown__title\">\n    <span>Cite</span>\n    <span class=\"hide-text-small\">paper</span>\n</h3>\n<ul class=\"citations__content\" data-role=\"button-dropdown__content\">\n    <li>\n        <a href=\"#citeas\" data-track=\"click\" data-track-action=\"Cite as link\" data-track-label=\"Cite dropdown\">How to cite?</a>\n    </li>\n        <li>\n            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;refman&amp;flavour&#x3D;citation\"\n               title=\"Download this paper&#39;s citation as a .RIS file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"RIS\">\n                <span class=\"citations__extension\" data-gtmlabel=\"RIS\">\n                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>\n                    .RIS\n                </span>\n                <span class=\"citations__types\">\n                        <span>\n                            Papers\n                        </span>\n                        <span>\n                            Reference Manager\n                        </span>\n                        <span>\n                            RefWorks\n                        </span>\n                        <span>\n                            Zotero\n                        </span>\n                </span>\n            </a>\n        </li>\n        <li>\n            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;endnote&amp;flavour&#x3D;citation\"\n               title=\"Download this paper&#39;s citation as a .ENW file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"ENW\">\n                <span class=\"citations__extension\" data-gtmlabel=\"ENW\">\n                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>\n                    .ENW\n                </span>\n                <span class=\"citations__types\">\n                        <span>\n                            EndNote\n                        </span>\n                </span>\n            </a>\n        </li>\n        <li>\n            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;bibtex&amp;flavour&#x3D;citation\"\n               title=\"Download this paper&#39;s citation as a .BIB file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"BIB\">\n                <span class=\"citations__extension\" data-gtmlabel=\"BIB\">\n                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>\n                    .BIB\n                </span>\n                <span class=\"citations__types\">\n                        <span>\n                            BibTeX\n                        </span>\n                        <span>\n                            JabRef\n                        </span>\n                        <span>\n                            Mendeley\n                        </span>\n                </span>\n            </a>\n        </li>\n</ul>\n    </div>\n\n                                                <div>\n        <a class=\"c-button share-this test-shareby-sharelink-link\" data-test=\"shareable-link\" target=\"_blank\" rel=\"noopener\" href=\"/sharelink/10.1007/978-3-319-40406-6_17\" data-track=\"click\" data-track-action=\"Share via\" data-track-label=\"ShareLink\">\n            <span>Share</span>\n            <span class=\"hide-text-small\">paper</span>\n        </a>\n    </div>\n\n\n\n\n                                    </div>\n                                </div>\n                                <nav class=\"toc\" aria-label=\"article contents\">\n    <h2 class=\"u-screenreader-only\" aria-hidden=\"true\">Table of contents</h2>\n    <ul id=\"article-contents\" class=\"article-contents\" tabindex=\"-1\">\n            <li>\n                <a title=\"Conference paper\" href=\"#enumeration\"><span class=\"u-overflow-ellipsis\">Conference paper</span></a>\n            </li>\n            <li>\n                <a title=\"Abstract\" href=\"#Abs1\"><span class=\"u-overflow-ellipsis\">Abstract</span></a>\n            </li>\n            <li>\n                <a title=\"Introduction\" href=\"#Sec1\"><span class=\"u-overflow-ellipsis\">Introduction</span></a>\n            </li>\n            <li>\n                <a title=\"Methodology Description\" href=\"#Sec2\"><span class=\"u-overflow-ellipsis\">Methodology Description</span></a>\n            </li>\n            <li>\n                <a title=\"Case Study of Photo Sharing Websites\" href=\"#Sec5\"><span class=\"u-overflow-ellipsis\">Case Study of Photo Sharing Websites</span></a>\n            </li>\n            <li>\n                <a title=\"Result\" href=\"#Sec8\"><span class=\"u-overflow-ellipsis\">Result</span></a>\n            </li>\n            <li>\n                <a title=\"Conclusion\" href=\"#Sec11\"><span class=\"u-overflow-ellipsis\">Conclusion</span></a>\n            </li>\n            <li>\n                <a title=\"References\" href=\"#Bib1\"><span class=\"u-overflow-ellipsis\">References</span></a>\n            </li>\n            <li>\n                <a title=\"Copyright information\" href=\"#copyrightInformation\"><span class=\"u-overflow-ellipsis\">Copyright information</span></a>\n            </li>\n            <li>\n                <a title=\"Authors and Affiliations\" href=\"#authorsandaffiliations\"><span class=\"u-overflow-ellipsis\">Authors and Affiliations</span></a>\n            </li>\n            <li>\n                <a title=\"About this paper\" href=\"#aboutcontent\"><span class=\"u-overflow-ellipsis\">About this paper</span></a>\n            </li>\n    </ul>\n</nav>\n\n                            </div>\n                                <div class=\"skyscraper-ad u-hide\" data-google-ad=\"skyscraper\" data-gpt-hide-ad>\n        <div class=\"skyscraper-ad__wrapper\">\n            <p class=\"skyscraper-ad__label\">Advertisement</p>\n            <button class=\"skyscraper-ad__hide\" title=\"Hide this advertisement\" data-gpt-hide-ad-button data-track=\"click\" data-track-action=\"Hide advertisement\" data-track-label=\"\">Hide</button>\n            <div id=\"doubleclick-ad\" class=\"skyscraper-ad__ad\" data-gpt></div>\n        </div>\n    </div>\n\n                        </div>\n                    </aside>\n                </div>\n            </main>\n                <footer class=\"footer u-interface\">\n        <div class=\"footer__aside-wrapper\">\n            <div class=\"footer__content\">\n                <div class=\"footer__aside\">\n                    <p class=\"footer__strapline\">Over 10 million scientific documents at your fingertips</p>\n                                <div class=\"footer__edition\" data-component=\"SV.EditionSwitcher\">\n                                    <h3 class=\"u-hide\" data-role=\"button-dropdown__title\" data-btn-text=\"Switch between Academic &#38; Corporate Edition\">Switch Edition</h3>\n                                    <ul data-role=\"button-dropdown__content\">\n                                        <li  class=\"selected\"><a href=\"/siteEdition/link?previousUrl=/chapter/10.1007%2F978-3-319-40406-6_17&id=siteedition-academic-link\" id=\"siteedition-academic-link\">Academic Edition</a></li>\n                                        <li ><a href=\"/siteEdition/rd?previousUrl=/chapter/10.1007%2F978-3-319-40406-6_17&id=siteedition-corporate-link\" id=\"siteedition-corporate-link\">Corporate Edition</a></li>\n                                    </ul>\n                                </div>\n                </div>\n            </div>\n        </div>\n        <div class=\"footer__content\">\n            <ul class=\"footer__nav\">\n                <li>\n                    <a href=\"/\">Home</a>\n                </li>\n                <li>\n                    <a href=\"/impressum\">Impressum</a>\n                </li>\n                <li>\n                    <a href=\"/termsandconditions\">Legal information</a>\n                </li>\n                <li>\n                    <a href=\"/privacystatement\">Privacy statement</a>\n                </li>\n                <li>\n                    <a href=\"https://www.springernature.com/ccpa\">California privacy statement</a>\n                </li>\n                <li>\n                    <a href=\"/cookiepolicy\">How we use cookies</a>\n                </li>\n                <li>\n                    <a class=\"optanon-toggle-display\" href=\"javascript:void(0);\">Manage cookies/Do not sell my data</a>\n                </li>\n                <li>\n                    <a href=\"/accessibility\">Accessibility</a>\n                </li>\n                <li>\n                    <a href=\"https://support.springer.com/en/support/home\">FAQ</a>\n                </li>\n                <li>\n                    <a id=\"contactus-footer-link\" href=\"https://support.springer.com/en/support/solutions/articles/6000206179-contacting-us\">Contact us</a>\n                </li>\n                <li>\n                    <a href=\"https://www.springer.com/gp/shop/promo/affiliate/springer-nature\">Affiliate program</a>\n                </li>\n            </ul>\n            <a class=\"parent-logo\"\n               target=\"_blank\" rel=\"noopener\"\n               href=\"//www.springernature.com\"\n               title=\"Go to Springer Nature\">\n                <span class=\"u-screenreader-only\">Springer Nature</span>\n                <svg width=\"125\" height=\"12\" focusable=\"false\" aria-hidden=\"true\">\n                    <image width=\"125\" height=\"12\"\n                           src=\"/springerlink-static/1923692707/images/png/springernature.png\"\n                           xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n                           xlink:href=\"/springerlink-static/1923692707/images/svg/springernature.svg\">\n                    </image>\n                </svg>\n            </a>\n\n            <p class=\"footer__copyright\">&copy; 2020 Springer Nature Switzerland AG. Part of <a target=\"_blank\" rel=\"noopener\" href=\"//www.springernature.com\">Springer Nature</a>.</p>\n                <p class=\"footer__user-access-info\">\n                    <span>Not logged in</span>\n                    <span>Not affiliated</span>\n                    <span>201.35.134.227</span>\n                </p>\n        </div>\n    </footer>\n\n        </div>\n        <script type=\"text/javascript\">\n    (function() {\n        var linkEl = document.querySelector('.js-ctm');\n        var scriptsList = [];\n        var polyfillFeatures = '';\n\n        window.SpringerLink = window.SpringerLink || {};\n        window.SpringerLink.staticLocation = '/springerlink-static/1923692707';\n        window.eventTrackerInstance = null;\n\n        if (window.matchMedia && window.matchMedia(linkEl.media).matches) {\n            (function(h){h.className = h.className.replace('no-js', 'js')})(document.documentElement);\n\n            polyfillFeatures = 'default,fetch,Promise,Object.setPrototypeOf,Object.entries,Number.isInteger,MutationObserver,startsWith,Array.prototype.includes,Array.from,IntersectionObserver';\n\n            scriptsList = [\n                'https://cdn.polyfill.io/v2/polyfill.min.js?features=' + polyfillFeatures + '&flags=gated',\n                window.SpringerLink.staticLocation + '/js/main.js'\n            ];\n\n            scriptsList.forEach(function(script) {\n                var tag = document.createElement('script');\n                tag.async = false;\n                tag.src = script;\n\n                document.body.appendChild(tag);\n            });\n        }\n    })();\n</script>\n\n    <script>\n    (function() {\n        var linkEl = document.querySelector('.js-ctm');\n        if (window.matchMedia && window.matchMedia(linkEl.media).matches) {\n            var scriptMathJax = document.createElement('script');\n            scriptMathJax.async = false;\n            scriptMathJax.src = '/springerlink-static/1923692707/js/mathJax.js';\n            var s0 = document.getElementsByTagName('script')[0];\n            s0.parentNode.insertBefore(scriptMathJax, s0);\n        }\n    })();\n</script>\n\n\n    <script type=\"text/javascript\" id=\"googletag-push\">\n        \n            var adSlot = '270604982/springerlink/book/chapter';\n        \n\n        var definedSlots = [\n                {slot: [728, 90], containerName: 'doubleclick-leaderboard-ad'},\n                {slot: [160, 600], containerName: 'doubleclick-ad'},\n            {slot: [2, 2], containerName: 'doubleclick-native-ad'}\n        ];\n    </script>\n\n\n        \n        <span id=\"chat-widget\" class=\"u-hide\"></span>\n                    <noscript>\n                <img aria-hidden=\"true\" role=\"presentation\" src=\"https://ssl-springer.met.vgwort.de/na/vgzm.415900-10.1007-978-3-319-40406-6_17\" width='1' height='1' alt='' />\n            </noscript>\n\n        \n    </body>\n</html>\n", "response": ["GET /10.1007/978-3-319-40406-6_17 HTTP/1.1", "Host: link.springer.com", "User-Agent: PostmanRuntime/7.28.4", "Accept-Encoding: gzip, deflate", "Accept: */*", "Connection: keep-alive", "HTTP/1.1 302 Found", "Connection: keep-alive", "Content-Length: 0", "Cache-Control: max-age=0", "Expires: Tue, 30 Nov 2021 20:25:43 GMT", "Location: https://idp.springer.com/authorize?redirect_uri=https://link.springer.com/10.1007/978-3-319-40406-6_17&client_id=springerlink&response_type=cookie", "Server: Oscar Platform 0.352.0", "X-Environment: live", "X-Frame-Options: DENY", "X-Origin-Server: 00e6918d-0388-4178-5344-2d13", "X-Vcap-Request-Id: 87deaabf-24e9-4b7f-6a4a-c3ced9f537e2", "Via: 1.1 google, 1.1 varnish", "X-Cdn-Origin: SNPaaS", "Accept-Ranges: bytes", "Date: Tue, 30 Nov 2021 20:25:43 GMT", "Age: 0", "X-Served-By: cache-9638c60b-internal, cache-cwb20526-CWB", "X-Cache: MISS, MISS", "X-Cache-Hits: 0", "X-Timer: S1638303943.100499,VS0,VE221", "GET /authorize?redirect_uri=https://link.springer.com/10.1007/978-3-319-40406-6_17&client_id=springerlink&response_type=cookie HTTP/1.1", "Host: idp.springer.com", "User-Agent: PostmanRuntime/7.28.4", "Accept-Encoding: gzip, deflate", "Accept: */*", "Connection: keep-alive", "HTTP/1.1 302 Found", "Connection: keep-alive", "Content-Length: 0", "Cache-Control: no-cache, no-store, max-age=0, must-revalidate", "Expires: 0", "Location: https://idp.springer.com/transit?redirect_uri=https%3A%2F%2Flink.springer.com%2F10.1007%2F978-3-319-40406-6_17&code=60fe231f-d417-4b01-a868-705fcf1f7a9a", "Pragma: no-cache", "Set-Cookie: idp_session=sVERSION_16fab3d25-4635-4f56-9bb6-2d4fdb64abc6; Domain=.springer.com; Path=/; Secure; HttpOnly", "Set-Cookie: idp_session_http=hVERSION_19fac8fd4-6b69-4d64-8f9d-56fa553407b2; Domain=.springer.com; Path=/; HttpOnly", "Set-Cookie: idp_marker=13b1d7b2-0d9e-40e0-a782-190fe3f7a066; Domain=.springer.com; Path=/; Max-Age=315360000; HttpOnly", "Strict-Transport-Security: max-age=31536000 ; includeSubDomains", "X-B3-Spanid: 555cee41a18762e7", "X-B3-Traceid: 555cee41a18762e7", "X-Content-Type-Options: nosniff", "X-Frame-Options: DENY", "X-Vcap-Request-Id: aa939d64-9d1d-4132-595e-8a6ee2870196", "X-Xss-Protection: 1; mode=block", "Via: 1.1 google, 1.1 varnish", "X-Cdn-Origin: SNPaaS", "Accept-Ranges: bytes", "Date: Tue, 30 Nov 2021 20:25:43 GMT", "X-Served-By: cache-cgh11157-CGH", "X-Cache: MISS", "X-Cache-Hits: 0", "X-Timer: S1638303943.402903,VS0,VE214", "Vary: x-forwarded-proto", "GET /transit?redirect_uri=https%3A%2F%2Flink.springer.com%2F10.1007%2F978-3-319-40406-6_17&code=60fe231f-d417-4b01-a868-705fcf1f7a9a HTTP/1.1", "Host: idp.springer.com", "User-Agent: PostmanRuntime/7.28.4", "Accept-Encoding: gzip, deflate", "Accept: */*", "Connection: keep-alive", "Cookie: idp_session=sVERSION_16fab3d25-4635-4f56-9bb6-2d4fdb64abc6; idp_session_http=hVERSION_19fac8fd4-6b69-4d64-8f9d-56fa553407b2; idp_marker=13b1d7b2-0d9e-40e0-a782-190fe3f7a066", "HTTP/1.1 302 Found", "Connection: keep-alive", "Content-Length: 0", "Cache-Control: no-cache, no-store, max-age=0, must-revalidate", "Content-Language: en-US", "Expires: 0", "Location: https://link.springer.com/10.1007/978-3-319-40406-6_17", "Pragma: no-cache", "Strict-Transport-Security: max-age=31536000 ; includeSubDomains", "X-B3-Spanid: 766ec5957938e74b", "X-B3-Traceid: 766ec5957938e74b", "X-Content-Type-Options: nosniff", "X-Frame-Options: DENY", "X-Vcap-Request-Id: e44ae641-43b1-4f56-713c-f5dcab6b4422", "X-Xss-Protection: 1; mode=block", "Via: 1.1 google, 1.1 varnish", "X-Cdn-Origin: SNPaaS", "Accept-Ranges: bytes", "Date: Tue, 30 Nov 2021 20:25:43 GMT", "X-Served-By: cache-cgh11157-CGH", "X-Cache: MISS", "X-Cache-Hits: 0", "X-Timer: S1638303944.644810,VS0,VE209", "Vary: x-forwarded-proto", "GET /10.1007/978-3-319-40406-6_17 HTTP/1.1", "Host: link.springer.com", "User-Agent: PostmanRuntime/7.28.4", "Accept-Encoding: gzip, deflate", "Accept: */*", "Connection: keep-alive", "Cookie: idp_marker=13b1d7b2-0d9e-40e0-a782-190fe3f7a066; idp_session=sVERSION_16fab3d25-4635-4f56-9bb6-2d4fdb64abc6; idp_session_http=hVERSION_19fac8fd4-6b69-4d64-8f9d-56fa553407b2", "HTTP/1.1 302 Found", "Connection: keep-alive", "Content-Length: 0", "Age: 0", "Cache-Control: max-age=0", "Content-Type: text/html;charset=utf-8", "Expires: Thu, 01 Jan 1970 00:00:00 GMT", "Location: https://link.springer.com/chapter/10.1007%2F978-3-319-40406-6_17", "Server: Oscar Platform 0.352.0", "Set-Cookie: trackid=6cd8357f2fba4eb3b7f60fb08; Path=/; Domain=.springer.com; Secure; HttpOnly", "X-Environment: live", "X-Frame-Options: DENY", "X-Origin-Server: b5aeedf0-e4e6-492a-5e97-603b", "X-Vcap-Request-Id: 2876a305-c763-43b6-448d-89c586bf7dbc", "Via: 1.1 google, 1.1 varnish", "X-Cdn-Origin: SNPaaS", "Accept-Ranges: bytes", "Date: Tue, 30 Nov 2021 20:25:44 GMT", "X-Served-By: cache-b21f2443-internal, cache-cwb20526-CWB", "X-Cache: MISS, MISS", "X-Cache-Hits: 0", "X-Timer: S1638303944.877175,VS0,VE234", "GET /chapter/10.1007%2F978-3-319-40406-6_17 HTTP/1.1", "Host: link.springer.com", "User-Agent: PostmanRuntime/7.28.4", "Accept-Encoding: gzip, deflate", "Accept: */*", "Connection: keep-alive", "Cookie: idp_marker=13b1d7b2-0d9e-40e0-a782-190fe3f7a066; idp_session=sVERSION_16fab3d25-4635-4f56-9bb6-2d4fdb64abc6; idp_session_http=hVERSION_19fac8fd4-6b69-4d64-8f9d-56fa553407b2; trackid=6cd8357f2fba4eb3b7f60fb08", "HTTP/1.1 200 OK", "Connection: keep-alive", "Accept-Ranges: bytes", "Age: 0", "Cache-Control: private, max-age=0, must-revalidate", "Content-Encoding: gzip", "Content-Type: text/html;charset=utf-8", "Expires: Thu, 01 Jan 1970 00:00:00 GMT", "Referrer-Policy: origin", "Server: Oscar Platform 0.352.0", "Set-Cookie: sim-inst-token=1::1638333944314:cc4fbddf; Path=/; Domain=.springer.com; Secure; HttpOnly", "Strict-Transport-Security: max-age=3600; includeSubDomains", "X-B3-Parentspanid: ", "X-B3-Sampled: 0", "X-B3-Spanid: 8f76a3d951516309", "X-B3-Traceid: 8f76a3d951516309", "X-Content-Type-Options: nosniff", "X-Frame-Options: DENY", "X-Vcap-Request-Id: 2332a6ba-1c99-443a-7078-6f540b60084e", "Via: 1.1 google, 1.1 varnish", "X-Cdn-Origin: SNPaaS", "Date: Tue, 30 Nov 2021 20:25:44 GMT", "X-Served-By: cache-b4f29801-internal, cache-cwb20526-CWB", "X-Cache: MISS, MISS", "X-Cache-Hits: 0", "X-Timer: S1638303944.133167,VS0,VE487", "Vary: Accept-Encoding", "transfer-encoding: chunked", "<!DOCTYPE HTML>", "<html lang=\"en-gb\" class=\"no-js\">", "    <head>", "        <meta charset=\"utf-8\">", "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge,chrome=1\"/>", "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=2.5,user-scalable=yes\">", "    <meta name=\"citation_publisher\" content=\"Springer, Cham\"/>", "    <meta name=\"citation_title\" content=\"The Exploration of User Knowledge Architecture Based on Mining User Generated Contents \u2013 An Application Case of Photo-Sharing Website\"/>", "    <meta name=\"citation_doi\" content=\"10.1007/978-3-319-40406-6_17\"/>", "    <meta name=\"citation_language\" content=\"en\"/>", "    <meta name=\"citation_abstract_html_url\" content=\"https://link.springer.com/chapter/10.1007/978-3-319-40406-6_17\"/>", "    <meta name=\"citation_fulltext_html_url\" content=\"https://link.springer.com/chapter/10.1007/978-3-319-40406-6_17\"/>", "    <meta name=\"citation_pdf_url\" content=\"https://link.springer.com/content/pdf/10.1007%2F978-3-319-40406-6_17.pdf\"/>", "    <meta name=\"citation_springer_api_url\" content=\"http://api.springer.com/metadata/pam?q=doi:10.1007/978-3-319-40406-6_17&amp;api_key=\"/>", "    <meta name=\"citation_firstpage\" content=\"180\"/>", "    <meta name=\"citation_lastpage\" content=\"192\"/>", "    <meta name=\"citation_author\" content=\"Liang, Nan\"/>", "    <meta name=\"citation_author_institution\" content=\"S.J.T.U.\"/>", "    <meta name=\"citation_author\" content=\"Zhong, Jiaming\"/>", "    <meta name=\"citation_author_institution\" content=\"S.J.T.U.\"/>", "    <meta name=\"citation_author\" content=\"Wang, Di\"/>", "    <meta name=\"citation_author_institution\" content=\"S.J.T.U.\"/>", "    <meta name=\"citation_author\" content=\"Zhang, Liqun\"/>", "    <meta name=\"citation_author_institution\" content=\"S.J.T.U.\"/>", "    <meta name=\"citation_author_email\" content=\"zhanglq@sjtu.edu.cn\"/>", "    <meta name=\"dc.identifier\" content=\"10.1007/978-3-319-40406-6_17\"/>", "    <meta name=\"format-detection\" content=\"telephone=no\"/>", "    <meta name=\"citation_fulltext_world_readable\" content=\"\"/>", "    <meta name=\"description\" content=\"Traditional methods to obtain user needs, such as interview, have exposed the increasingly serious problem of bias and inefficiency when meeting the blooming of users. This research tried to...\"/>", "    <meta name=\"twitter:card\" content=\"summary\"/>", "    <meta name=\"twitter:title\" content=\"The Exploration of User Knowledge Architecture Based on Mining User Ge\"/>", "    <meta name=\"twitter:image\" content=\"https://static-content.springer.com/cover/book/978-3-319-40406-6.jpg\"/>", "    <meta name=\"twitter:image:alt\" content=\"Content cover image\"/>", "    <meta name=\"twitter:site\" content=\"SpringerLink\"/>", "    <meta name=\"twitter:description\" content=\"Traditional methods to obtain user needs, such as interview, have exposed the increasingly serious problem of bias and inefficiency when meeting the blooming of users. This research tried to...\"/>", "    <meta name=\"citation_inbook_title\" content=\"Design, User Experience, and Usability: Technological Contexts\"/>", "    <meta name=\"citation_publication_date\" content=\"2016/7/17\"/>", "    <meta name=\"citation_conference_series_id\" content=\"springer/duxu\"/>", "    <meta name=\"citation_conference_title\" content=\"International Conference of Design, User Experience, and Usability\"/>", "    <meta name=\"citation_conference_sequence_num\" content=\"5\"/>", "    <meta name=\"citation_conference_abbrev\" content=\"DUXU\"/>", "    <meta property=\"og:title\" content=\"The Exploration of User Knowledge Architecture Based on Mining User Generated Contents \u2013 An Application Case of Photo-Sharing Website\"/>", "    <meta property=\"og:type\" content=\"Paper\"/>", "    <meta property=\"og:url\" content=\"https://link.springer.com/chapter/10.1007/978-3-319-40406-6_17\"/>", "    <meta property=\"og:image\" content=\"https://static-content.springer.com/cover/book/978-3-319-40406-6.jpg\"/>", "    <meta property=\"og:site_name\" content=\"SpringerLink\"/>", "    <meta property=\"og:description\" content=\"Traditional methods to obtain user needs, such as interview, have exposed the increasingly serious problem of bias and inefficiency when meeting the blooming of users. This research tried to...\"/>", "        <title>The Exploration of User Knowledge Architecture Based on Mining User Generated Contents \u2013 An Application Case of Photo-Sharing Website | SpringerLink</title>", "        <link rel=\"canonical\" href=\"https://link.springer.com/chapter/10.1007/978-3-319-40406-6_17\"/>", "        <link rel=\"shortcut icon\" href=\"/springerlink-static/1923692707/images/favicon/favicon.ico\">", "<link rel=\"icon\" sizes=\"16x16 32x32 48x48\" href=\"/springerlink-static/1923692707/images/favicon/favicon.ico\">", "<link rel=\"icon\" sizes=\"16x16\" type=\"image/png\" href=\"/springerlink-static/1923692707/images/favicon/favicon-16x16.png\">", "<link rel=\"icon\" sizes=\"32x32\" type=\"image/png\" href=\"/springerlink-static/1923692707/images/favicon/favicon-32x32.png\">", "<link rel=\"icon\" sizes=\"48x48\" type=\"image/png\" href=\"/springerlink-static/1923692707/images/favicon/favicon-48x48.png\">", "<link rel=\"apple-touch-icon\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-iphone@3x.png\">", "<link rel=\"apple-touch-icon\" sizes=\"72x72\" href=\"/springerlink-static/1923692707/images/favicon/ic_launcher_hdpi.png\">", "<link rel=\"apple-touch-icon\" sizes=\"76x76\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-ipad.png\">", "<link rel=\"apple-touch-icon\" sizes=\"114x114\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-114x114.png\">", "<link rel=\"apple-touch-icon\" sizes=\"120x120\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-iphone@2x.png\">", "<link rel=\"apple-touch-icon\" sizes=\"144x144\" href=\"/springerlink-static/1923692707/images/favicon/ic_launcher_xxhdpi.png\">", "<link rel=\"apple-touch-icon\" sizes=\"152x152\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-ipad@2x.png\">", "<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/springerlink-static/1923692707/images/favicon/app-icon-iphone@3x.png\">", "<meta name=\"msapplication-TileColor\" content=\"#ffffff\">", "<meta name=\"msapplication-TileImage\" content=\"/springerlink-static/1923692707/images/favicon/ic_launcher_xxhdpi.png\">", "        <link rel=\"dns-prefetch\" href=\"//fonts.gstatic.com\">", "<link rel=\"dns-prefetch\" href=\"//fonts.googleapis.com\">", "<link rel=\"dns-prefetch\" href=\"//google-analytics.com\">", "<link rel=\"dns-prefetch\" href=\"//www.google-analytics.com\">", "<link rel=\"dns-prefetch\" href=\"//www.googletagservices.com\">", "<link rel=\"dns-prefetch\" href=\"//www.googletagmanager.com\">", "<link rel=\"dns-prefetch\" href=\"//static-content.springer.com\">", "        <link rel=\"stylesheet\" href=\"/springerlink-static/1923692707/css/basic.css\" media=\"screen\">", "<link rel=\"stylesheet\" href=\"/springerlink-static/1923692707/css/styles.css\" class=\"js-ctm\" media=\"only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)\">", "<link rel=\"stylesheet\" href=\"/springerlink-static/1923692707/css/print.css\" media=\"print\">", "        <script>", "    (function () {", "        if ( typeof window.CustomEvent === \"function\" ) return;", "        window.CustomEvent = function ( event, params ) {", "            params = params || { bubbles: false, cancelable: false, detail: null };", "            var evt = document.createEvent( 'CustomEvent' );", "            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );", "            return evt;", "        }", "    })();", "</script>", "<script>", "    (function() {", "        if (!!document.documentElement.dataset) return;", "        Object.defineProperty(Element.prototype, 'dataset', {", "            get: function() {", "                var element = this;", "                var attributes = this.attributes;", "                var map = {};", "                for (var i = 0; i < attributes.length; i++) {", "                    var attribute = attributes[i];", "                    if (attribute && attribute.name && (/^data-\\w[\\w-]*$/).test(attribute.name)) {", "                        var name = attribute.name;", "                        var value = attribute.value;", "                        var propName = name.substr(5).replace(/-./g, function (prop) {", "                            return prop.charAt(1).toUpperCase();", "                        });", "                        Object.defineProperty(map, propName, {", "                            enumerable: true,", "                            get: function() {", "                                return this.value;", "                            }.bind({value: value || ''}),", "                            set: function setter(name, value) {", "                                if (typeof value !== 'undefined') {", "                                    this.setAttribute(name, value);", "                                } else {", "                                    this.removeAttribute(name);", "                                }", "                            }.bind(element, name)", "                        });", "                    }", "                }", "                return map;", "            }", "        });", "    })();", "</script>", "    <script type=\"text/javascript\">", "        window.Krux||((Krux=function(){Krux.q.push(arguments);}).q=[]);", "        var dataLayer = [{", "                'GA Key':\"UA-26408784-1\",", "                'Features':[\"leaderboardadverts\",\"eventtracker\"],", "                'Event Category':\"Conference Paper\",", "                'Open Access':\"N\",", "                'Labs':\"Y\",", "                'DOI':\"10.1007/978-3-319-40406-6_17\",", "                'productId':\"9783319404066\",", "                'hasAccess':\"Y\",", "                'Full HTML':\"Y\",", "                'Has Body':\"Y\",", "                'Static Hash':\"1923692707\",", "                'Has Preview':\"N\",", "                'user':{\"license\":{\"businessPartnerID\":[],\"businessPartnerIDString\":\"\"}},", "                'content':{\"serial\":{\"eissn\":\"1611-3349\",\"pissn\":\"0302-9743\"},\"book\":{\"seriesTitle\":\"Lecture Notes in Computer Science\",\"eisbn\":\"978-3-319-40406-6\",\"pisbn\":\"978-3-319-40405-9\",\"bookProductType\":\"Proceedings\",\"seriesId\":\"558\",\"title\":\"Design, User Experience, and Usability: Technological Contexts\",\"doi\":\"10.1007/978-3-319-40406-6\"},\"attributes\":{\"deliveryPlatform\":\"bunsen\"},\"chapter\":{\"doi\":\"10.1007/978-3-319-40406-6_17\"},\"category\":{\"pmc\":{\"primarySubject\":\"Computer Science\",\"primarySubjectCode\":\"I\",\"secondarySubjects\":{\"4\":\"Information Storage and Retrieval\",\"5\":\"Software Engineering\",\"1\":\"User Interfaces and Human Computer Interaction\",\"2\":\"Computers and Society\",\"3\":\"Information Systems Applications (incl. Internet)\"},\"secondarySubjectCodes\":{\"4\":\"I18032\",\"5\":\"I14029\",\"1\":\"I18067\",\"2\":\"I24040\",\"3\":\"I18040\"}},\"sucode\":\"SUCO11645\"},\"type\":\"ConferencePaper\"},", "                'Access Type':\"subscription\",", "                'Page':\"chapter\",", "                'Bpids':\"\",", "                'Bpnames':\"\",", "                'SubjectCodes':\"SCI, SCI18067, SCI24040, SCI18040, SCI18032, SCI14029\",", "                'session':{\"authentication\":{\"loginStatus\":\"N\"},\"attributes\":{\"edition\":\"academic\"}},", "                'eventTrackerBaseUrl':\"https://event-tracker.springernature.com\",", "                'Keywords':\"Image, Content analysis, User knowledge, Experience, Photo sharing site\",", "                'Country':\"BR\",", "                'ConferenceSeriesId':\"duxu\",", "                'VG Wort Identifier':\"vgzm.415900-10.1007-978-3-319-40406-6\",", "                    'doi': \"10.1007-978-3-319-40406-6_17\",", "                    'kwrd': [\"Image\",\"Content_analysis\",\"User_knowledge\",\"Experience\",\"Photo_sharing_site\"],", "                    'pmc': [\"I\",\"I18067\",\"I24040\",\"I18040\",\"I18032\",\"I14029\"],", "                    'BPID': [\"1\"],", "                    'ksg': Krux.segments,", "                    'kuid': Krux.uid,", "        }];", "    </script>", "    <script>", "        window.dataLayer.push({", "            content: {", "                attributes: {", "                    deliveryPlatform: \"bunsen\"", "                }", "            }", "        });", "    </script>", "<script type=\"text/javascript\" src=\"/springerlink-static/1923692707/js/jquery-3.3.1.min.js\"></script>", "<script>", "    (function() {", "        function deleteCookie (name, domain) {", "            document.cookie = encodeURIComponent(name) +", "                '=' +", "                ';path=/' +", "                ';domain=' + domain +", "                ';expires=Thu, 01 Jan 1970 00:00:00 GMT';", "        }", "        var consentCookieParts = ('; ' + document.cookie).split('; OptanonConsent=');", "        if (consentCookieParts.length > 1) {", "            consentCookieParts.shift(); // remove redundant first part from the split array", "            // onetrust can set the same cookie multiple times with different domain specificities", "            for (let i=0; i<consentCookieParts.length; i++) {", "                var otCookieGroups = consentCookieParts[i].split('&groups=').pop().split('&').shift();", "                if (otCookieGroups.indexOf('C0001') === -1) {", "                    deleteCookie('OptanonConsent', window.location.host);", "                    deleteCookie('OptanonAlertBoxClosed', window.location.host);", "                }", "            }", "        }", "    })();", "</script>", "<script>", "    (function(w,d,t) {", "        function cc() {", "            var h = w.location.host, id;", "            if (h === 'link.springer.com' || h === 'local-link.springer.com' || h === 'link-qa.springer.com') { id = '4f53bc14-4ee3-45bd-9935-e3d2b6b2a543'}", "            if (h === 'rd.springer.com' || h === 'local-rd.springer.com' || h === 'rd-qa.springer.com') { id = 'ee0bb2c1-7bb6-4b9a-bbfe-41fc45438f37'}", "            var e = d.createElement(t),", "                s = d.getElementsByTagName(t)[0];", "            if (id) {", "                e.src = 'https://cdn.cookielaw.org/scripttemplates/otSDKStub.js';", "                e.setAttribute('data-domain-script', id);", "            } else {", "                e.src = '/static/js/lib/cookie-consent.min.js';", "                e.setAttribute('data-consent', h);", "            }", "            s.parentNode.insertBefore(e, s);", "        }", "        w.google_tag_manager ? cc() : window.addEventListener('gtm_loaded', function() {cc()});", "    })(window,document,'script');", "</script>", "<script>", "    function OptanonWrapper() {", "        window.dataLayer.push({ event:'OneTrustGroupsUpdated' });", "        document.activeElement.blur();", "    }", "</script>", "    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':", "                new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],", "            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=", "            'https://www.googletagmanager.com/gtm.js?id='+i+dl;", "            j.addEventListener('load', function() {", "                var _ge = new CustomEvent('gtm_loaded', {bubbles: true});", "                d.dispatchEvent(_ge);", "            });", "            f.parentNode.insertBefore(j,f);", "    })(window,document,'script','dataLayer','GTM-WCF9Z9');</script>", "    </head>", "    <body>", "        <noscript><iframe src=\"//www.googletagmanager.com/ns.html?id=GTM-WCF9Z9\"", "                      height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>", "    <div class=\"skip-to\">", "    <a class=\"skip-to__link pseudo-focus\" href=\"#main-content\">Skip to main content</a>", "        <a class=\"skip-to__link skip-to__link--contents pseudo-focus\" href=\"#article-contents\">Skip to sections</a>", "</div>", "        <div class=\"page-wrapper\">", "            <noscript>", "    <div class=\"nojs-banner u-interface\">", "        <p>This service is more advanced with JavaScript available</p>", "    </div>", "</noscript>", "                        <div id=\"leaderboard\" class=\"leaderboard u-hide\" data-google-ad=\"leaderboard\" data-gpt-hide-ad>", "            <div class=\"leaderboard__wrapper\">", "                <p class=\"leaderboard__label\">Advertisement</p>", "                <button class=\"leaderboard__hide\" title=\"Hide this advertisement\" data-gpt-hide-ad-button data-track=\"click\" data-track-action=\"Hide advertisement\" data-track-label=\"\">Hide</button>", "                <div id=\"doubleclick-leaderboard-ad\" class=\"leaderboard__ad u-pt-24\" data-gpt></div>", "            </div>", "        </div>", "                <header id=\"header\" class=\"header\">", "        <div class=\"header__content\">", "            <div class=\"header__menu-container\">", "                    <a id=\"logo\" class=\"site-logo\" href=\"/\" title=\"Go to homepage\">", "            <picture>", "    <source type=\"image/svg+xml\" srcset=\"/springerlink-static/1923692707/images/svg/springerlink.svg\">", "    <img class=\"site-logo__springer\" src=\"/springerlink-static/1923692707/images/png/springerlink.png\" alt=\"SpringerLink\" width=\"148\" height=\"30\" data-test=\"springer-logo\">", "</picture>", "    </a>", "                    <nav id=\"search-container\" class=\"u-inline-block\">", "                        <div class=\"search\">", "                            <div class=\"search__content\">", "                                <form class=\"u-form-single-input u-system\" action=\"/search\" method=\"get\" role=\"search\">", "    <label for=\"search-springerlink\">Search SpringerLink</label>", "    <div class=\"u-relative\">", "        <input id=\"search-springerlink\" name=\"query\" type=\"text\" autocomplete=\"off\" value=\"\">", "        <input class=\"u-hide-text\" type=\"submit\" value=\"Submit\" title=\"Submit\">", "        <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"13\" height=\"13\" class=\"u-vertical-align-absolute\" focusable=\"false\" aria-hidden=\"true\" role=\"presentation\">", "            <path d=\"M12.82 11.972a.607.607 0 01.007.856.611.611 0 01-.856-.006L9.45 10.3A5.798 5.797 0 010 5.798 5.798 5.797 0 1110.3 9.45zm-7.022-1.205A4.97 4.97 0 105.797.83a4.97 4.97 0 000 9.939z\" fill-rule=\"evenodd\"/>", "        </svg>", "    </div>", "</form>", "                            </div>", "                        </div>", "                    </nav>", "                    <nav class=\"nav-container\">", "    <div class=\"global-nav__wrapper\">", "        <div class=\"search-button\">", "            <a class=\"search-button__label\" href=\"#search-container\">", "                <span class=\"search-button__title\">Search</span>", "                <svg class=\"u-vertical-align-absolute\" xmlns=\"http://www.w3.org/2000/svg\" height=\"22\" width=\"22\" focusable=\"false\" aria-hidden=\"true\" role=\"presentation\">", "                    <path fill-rule=\"evenodd\" d=\"M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z\"/>", "                </svg>", "            </a>", "        </div>", "        <ul class=\"global-nav\" data-component=\"SV.Menu\" data-title=\"Navigation menu\" data-text=\"Menu\">", "            <li>", "                <a href=\"/\">", "                    <span class=\"u-overflow-ellipsis\">Home</span>", "                </a>", "            </li>", "                <li class=\"global-nav__logged-out\">", "                    <a class=\"test-login-link\" href=\"//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%252F978-3-319-40406-6_17\">", "                        <span class=\"u-overflow-ellipsis\">Log in</span>", "                    </a>", "                </li>", "        </ul>", "    </div> ", "</nav> ", "            </div>", "        </div>", "    </header>", "            ", "            <main id=\"main-content\" class=\"main-wrapper main-wrapper--no-gradient\" tabindex=\"-1\">", "                <div class=\"main-container uptodate-recommendations-off\">", "                    <aside class=\"main-sidebar-left\">", "                        <div class=\"main-sidebar-left__content\">", "                            <div class=\"cover-image test-cover\" itemscope>", "                                    <a class=\"test-cover-link\" href=\"/book/10.1007/978-3-319-40406-6\">", "        <span class=\"u-screenreader-only\">Design, User Experience, and Usability: Technological Contexts</span>", "        <img class=\"test-cover-image\" src=\"https://media.springernature.com/w306/springer-static/cover/book/978-3-319-40406-6.jpg\" itemprop=\"image\" alt=\"\"/>", "    </a>", "                            </div>", "                        </div>", "                    </aside>", "                    <div class=\"main-body\" data-role=\"NavigationContainer\">", "                        ", "                        <article class=\"main-body__content\">", "                            <div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"FulltextWrapper\"><div class=\"ArticleHeader main-context\"><div id=\"enumeration\" class=\"enumeration\">    <div>", "        <a data-test=\"ConfSeriesLink\" href=\"/conference/duxu\">", "            <span data-test=\"ConfSeriesName\"> International Conference of Design, User Experience, and Usability</span>", "        </a>", "    </div>", "<p class=\"test-LocationInConferenceProceeding icon--meta-keyline\"><span data-test=\"ConferenceAcronym\">DUXU 2016</span>: <span class=\"BookTitle\"><a href=\"/book/10.1007/978-3-319-40406-6\" data-track=\"click\" data-track-action=\"Book title\" data-track-label=\"\">Design, User Experience, and Usability: Technological Contexts</a></span><span class=\"page-numbers-info\">", "                pp 180-192</span><span class=\"u-inline-block u-ml-4\"> |", "                <a href=\"#citeas\" data-track=\"click\" data-track-action=\"Cite as link\" data-track-label=\"Enumeration section\">Cite as</a></span></p></div><div class=\"MainTitleSection\"><h1 class=\"ChapterTitle\" lang=\"en\">The Exploration of User Knowledge Architecture Based on Mining User Generated Contents \u2013 An Application Case of Photo-Sharing Website</h1></div><div class=\"authors u-clearfix\" data-component=\"SpringerLink.Authors\"><ul class=\"u-interface u-inline-list authors__title\" data-role=\"AuthorsNavigation\"><li><span>Authors</span></li><li><a href=\"#authorsandaffiliations\" data-track=\"click\" data-track-action=\"Authors and affiliations tab\" data-track-label=\"\">Authors and affiliations</a></li></ul><div class=\"authors__list\" data-role=\"AuthorsList\"><ul class=\"test-contributor-names\"><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors__name\">Nan\u00a0Liang</span></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors__name\">Jiaming\u00a0Zhong</span></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors__name\">Di\u00a0Wang</span></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors__name\">Liqun\u00a0Zhang</span><span class=\"author-information\"><span class=\"authors__contact\"><a href=\"mailto:zhanglq@sjtu.edu.cn\" title=\"zhanglq@sjtu.edu.cn\" itemprop=\"email\" data-track=\"click\" data-track-action=\"Email author\" data-track-label=\"\"><img src=\"/springerlink-static/images/svg/email.svg\" height=\"24\" width=\"24\" alt=\"Email author\" /></a></span></span></li></ul></div></div><div class=\"main-context__container\" data-component=\"SpringerLink.ArticleMetrics\"><div class=\"main-context__column\"><span><span class=\"test-render-category\">Conference paper</span></span><div class=\"article-dates\"><span class=\"article-dates__label\">First Online: </span><span class=\"article-dates__first-online\"><time datetime=\"2016-06-22\">22 June 2016</time></span></div></div><div class=\"main-context__column\">    <ul id=\"book-metrics\" class=\"article-metrics u-sansSerif\">", "            <li class=\"article-metrics__item\">", "                    <a class=\"article-metrics__link gtm-chaptercitations-count\" href=\"https://citations.springer.com/item?doi&#x3D;10.1007/978-3-319-40406-6_17\" target=\"_blank\" rel=\"noopener\"", "                       title=\"Visit Springer Citations for full citation details\" id=\"chaptercitations-link\">", "                            <span id=\"chaptercitations-count-number\" class=\"test-metric-count c-button-circle gtm-chaptercitations-count\">2</span>", "                       <span class=\"test-metric-name article-metrics__label gtm-chaptercitations-count\">Citations</span>", "                    </a>", "            </li>", "            <li class=\"article-metrics__item\">", "                     <span class=\"test-metric-count article-metrics__views\">1.8k</span>", "                     <span class=\"test-metric-name article-metrics__label\">Downloads</span>", "            </li>", "    </ul>", "</div></div><span id=\"test-SeriesTitle\" class=\"vol-info\">", "                Part of the", "                <a class=\"gtm-book-series-link\" href=\"/bookseries/558\">Lecture Notes in Computer Science</a>", "                book series (LNCS, volume 9748)</span></div><section class=\"Abstract\" id=\"Abs1\" tabindex=\"-1\" lang=\"en\"><h2 class=\"Heading\">Abstract</h2><p id=\"Par1\" class=\"Para\">Traditional methods to obtain user needs, such as interview, have exposed the increasingly serious problem of bias and inefficiency when meeting the blooming of users. This research tried to ameliorate the situation by mining user-generated data and constructing corresponding user knowledge systems with the help of modern technologies. With a photo-sharing website as a study case, several techniques have been implemented, including image feature extraction, content analysis and statistical calculation, to analyze users\u2019 characteristics and preferences. The results indicated that many of these techniques are practical and effective for future research in user experience design. It is foreseeable that the domain of this research can be expanded to text and voice to construct a synthesis approach for ultimately understanding users.</p></section><div class=\"KeywordGroup\" lang=\"en\"><h2 class=\"Heading\">Keywords</h2><span class=\"Keyword\">Image\u00a0</span><span class=\"Keyword\">Content analysis\u00a0</span><span class=\"Keyword\">User knowledge\u00a0</span><span class=\"Keyword\">Experience\u00a0</span><span class=\"Keyword\">Photo sharing site\u00a0</span></div><div class=\"note test-pdf-link\" id=\"cobranding-and-download-availability-text\"><div>    <a href=\"/content/pdf/10.1007%2F978-3-319-40406-6_17.pdf\" target=\"_blank\" rel=\"noopener\" data-track=\"click\" data-track-action=\"Pdf download\" data-track-label=\"\">Download</a>", " conference paper PDF</div></div><div class=\"article-actions--inline\" id=\"article-actions--inline\" data-component=\"article-actions--inline\"></div><div id=\"body\"><section id=\"Sec1\" tabindex=\"-1\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\"><span class=\"HeadingNumber\">1 </span>Introduction</h2><div class=\"content\"><p id=\"Par2\" class=\"Para\">In view of the considerable improvement of material living standard in recent years, designers begin to pay more attention to emotional and spiritual elements in their products and services. The major consideration of user experience design, or UED, is to create satisfying, aesthetic and innovative products which constantly meet user\u2019s needs and even lead the trend of modern lifestyle. Therefore, it is important for designers to understand user needs and further translate them into appropriate products. In the age of the Internet, the presence of blogs, forums, wiki, SNS and RSS combining with newly developed theories such as Six Degrees of Separation and the Long Tail, has made user knowledge into an open, complex and adaptive system. In the current web environment, there is an increasing diversity in the representing forms of user knowledge, while users usually feel easy to accommodate this situation. The problem is left to designers on both acquiring user knowledge and constructing corresponding systems.</p><p id=\"Par3\" class=\"Para\">The key of user research is mining the needs buried deeply in users\u2019 mind through their language and daily behavior. Traditional methods, including questionnaire, interview, observation, focus group and persona, achieve the goal through behavior observation and carefully designed conversation. Designers are required to have empathy and an open mind throughout the process. Otherwise, bad expressions may lead to different or even opposite answers, deviating from user\u2019s reality.</p><p id=\"Par4\" class=\"Para\">To certain extent, traditional methods reveal user needs, but suffer from poor efficiency and non-negligible influence of mood and environment. Hence, they are not suitable for researching on massive users. On the other hand, the original knowledge produced by users themselves better expresses their real thought. Big data technology has made it possible and cheaper to study large groups of users. Till now, it is frequently used in many fields like finance, online business, healthcare, social security and smart city, comparatively rare in that of design.</p><p id=\"Par5\" class=\"Para\">Data mining can be a new aspect for extending the study of user experience and user knowledge. This paper describes how to dig for user knowledge and understand their needs by large-scale data searching and image content analysis technologies and finally construct user knowledge system which ensures excellent user experience. The methods described in this paper are also good references to other design research.</p></div></section><section id=\"Sec2\" tabindex=\"-1\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\"><span class=\"HeadingNumber\">2 </span>Methodology Description</h2><div class=\"content\"><section id=\"Sec3\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">2.1 </span>Overview</h3><div id=\"Par6\" class=\"Para\">This paper mainly elucidate how we apply image feature recognition and content analysis technologies to obtain research variables, which are later estimated by statistical calculation, in order to acquire user knowledge and construct corresponding system. The detailed research process is as follows:<div class=\"UnorderedList\"><ul class=\"UnorderedListMarkBullet\"><li> <p id=\"Par7\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">How to acquire user knowledge?</strong> When using certain products or services, users would exchange information (namely words, images and voice) and this information could be recognized as \u201cuser knowledge\u201d since they directly reflect users\u2019 demands. For instance, users of photo sharing social websites interact with each other by uploading images, clicking \u201clike\u201d, commenting and reposting. In the process of this type of interactions, users undoubtedly leave \u201cinternet footprints\u201d as a part of user knowledge, which manifest their attention and preference.</p> </li><li> <p id=\"Par8\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">How to acquire users\u2019 footprints?</strong> In short, one could apply respective techniques to figure out the footprints left by users. For example, equipped with public programming interfaces exposed by relevant websites (e.g. WeChat API) and web crawler programs, one is able to get users\u2019 information such as images, texts, and voice, under certain agreement of privacy. The emerging of new technologies fulfills the purpose of image analysis, broadening the area of information capture and analysis.</p> </li><li> <p id=\"Par9\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Analysis methodology and tools.</strong> Three main methods have been exploited, including image feature identification, content analysis and statistical calculation.</p> </li></ul></div></div></section><section id=\"Sec4\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">2.2 </span>Details of Three Methods</h3><p id=\"Par10\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Image Feature Recognition.</strong> Three particular tools fall into this category.</p><p id=\"Par11\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Analyzing tools for color spatial distribution.</em> Based on pixel RGB values of sample images, this tool generates color spatial points and conducts clustering and dimension-reduction processing through vector calculation and principal component analysis. The result can help researchers analyze variation in color characteristics of samples from different users.</p><div id=\"Par12\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Extracting tools for sample dominant color tone.</em> Based on the calculation of pixel color features, this tool respectively generates the entire color constitution, by which the dominant 80\u00a0% colors of raw samples can be represented (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig2\">2</a></span>). After that, it will conduct batch processing analysis and generate a form for each sample, manifesting its dominant color tone for following analysis of multi-dimensional color deviation (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig1\">1</a></span>).", "<figure class=\"Figure\" id=\"Fig1\"><div class=\"MediaObject\" id=\"MO1\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig1_HTML.jpg\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig1_HTML.jpg\" alt=\"Fig.\u00a01.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a01.</span> <p class=\"SimplePara\">Extracting tools for sample dominant color (Color figure online)</p> </div></figcaption></figure><figure class=\"Figure\" id=\"Fig2\"><div class=\"MediaObject\" id=\"MO2\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig2_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig2_HTML.gif\" alt=\"Fig.\u00a02.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a02.</span> <p class=\"SimplePara\">Analyzing tools for the similarity of sample dominant colors (themeDistComputingTool_v1).</p> </div></figcaption></figure></div><p id=\"Par13\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Analyzing tools for the similarity of sample dominant color tone.</em> Depending on sample dominant color tone data, this tool calculates the dominant color tone similarity between each pair among 574 samples and generates csv format files as the input of statistical calculations in MDS analysis.</p><p id=\"Par14\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Content Analyzing Technology.</strong> Content analysis is a technology which analyzes the content of samples and generates a structured variable system to describe these samples by means of tags. The tags demonstrate the category and order description of the samples, in order to support future statistical analysis and search for similarity or differences.</p><p id=\"Par15\" class=\"Para\">Base on the overall analysis of samples, several descriptive variables have been proposed and labeled. In the scope of this research, all labels fall into one of the following six categories: picture type, picture theme, composition, means of expression, light and shade, image style.</p><p id=\"Par16\" class=\"Para\">Next, we introduce the notion of matrix of metrical data which is by definition a table for managing samples and corresponding variable labels. All assignment of values to variables results from combination of image feature and artificial labeling. Based on this matrix, all data is imported into SPSS after necessary normalization for next descriptive statistical analysis and advanced calculation.</p><p id=\"Par17\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Statistical Calculation.</strong> Statistical calculation provides a way to discover the internal relation between objective elements shown by pictures and subjective recognition of users, by means of clustering, multi-dimensional analysis and some other tools.</p><p id=\"Par18\" class=\"Para\">Correspondence analysis is the main statistical method used in this research. The connections between variables are represented graphically by interaction summary table. This analysis technique is suitable for situations with many qualitative variables in which connections between these variables of different categories is to be established. SPSS is a prevalent software for this kind of analysis.</p><p id=\"Par19\" class=\"Para\">Nowadays correspondence analysis is widely used in early-stage concept designing, in areas of developing new product, market positioning and advertisement. It has become an important tool for designers and market researchers to solve the problem of evaluating product property, competitor and targeting market.</p></section></div></section><section id=\"Sec5\" tabindex=\"-1\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\"><span class=\"HeadingNumber\">3 </span>Case Study of Photo Sharing Websites</h2><div class=\"content\"><p id=\"Par20\" class=\"Para\">Benefited from massive data mining technology, we selected a popular use case to launch our study which concentrated on constructing user knowledge of photo sharing websites and further analyzing the needs and psychological features of their active users.</p><p id=\"Par21\" class=\"Para\">Many user actions can be regarded as the process of producing user knowledge, including uploading photos and social operations such as clicking a like, commenting and reposting. In this scenario, user knowledge lies in the images, text and user actions. Although text usually indicates the exact thought of users, understanding the meaning by programming is very hard and most importantly text cannot reflect the relation between the image itself and users\u2019 judgement on it.</p><p id=\"Par22\" class=\"Para\">After careful consideration, the popular images in photo-sharing websites were chosen as the main object for studying, fulfilling the purpose of mining information apropos to images itself, user preferences and their relation.</p><section id=\"Sec6\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">3.1 </span>Selecting Target Website</h3><p id=\"Par23\" class=\"Para\">There are many well-known photo-sharing websites including Instagram, Lofter and Flickr by Yahoo. We finally chose Flickr after comparing the foundation date, number of users and some other aspects. Flickr is an image hosting and video hosting website and the web services suite was created by Ludicorp in 2004, acquired by Yahoo in 2005. It offers preeminent services including picture uploading and storing, classification, tagging and searching. Users need to fill in their profiles after registration and the profiles can help us in future study.</p><p id=\"Par24\" class=\"Para\">In the uploading process, users are required to give the picture a title, a description and some tags. For managing photos more effectively, users can create \u201cset\u201d, which is similar to a photo album.</p><div id=\"Par25\" class=\"Para\">Users of Flickr have various background, from professional photographers to PS amateur. All of them enjoy uploading their favorite photos, adding tags and descriptions and creating sets for them. Social operations are even more popular since everybody loves discovering beautiful pictures and grabbing attention of others reflected by the number of like and comments. The feature of a particular user can be revealed by the pictures s/he likes and hottest pictures manifest the inclination of most users. As a result, these hottest pictures provide us an effective way of getting the features we are studying, analyzing user disposition and finally construct user knowledge system of the website. The purpose of this study is exploring the type and features of popular pictures shared by Flickr users and describing their behaviors in Flickr (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig3\">3</a></span>).<figure class=\"Figure\" id=\"Fig3\"><div class=\"MediaObject\" id=\"MO3\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig3_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig3_HTML.gif\" alt=\"Fig.\u00a03.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a03.</span> <p class=\"SimplePara\">Flickr website</p> </div></figcaption></figure></div></section><section id=\"Sec7\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">3.2 </span>Process of Research</h3><p id=\"Par26\" class=\"Para\">Flickr holds an annual show named \u201cbest shot\u201d, selecting the most popular pictures of that year. We selected pictures from \u201c2015 best shot\u201d to narrow down the sample domain. Totally 574 pictures were filtered out through our crawler programs because they receive more than 99 comments or likes.</p><div id=\"Par27\" class=\"Para\">Based on previous state-of-the-art studies, we divided all labels into 6 categories.<div class=\"UnorderedList\"><ul class=\"UnorderedListMarkBullet\"><li> <p id=\"Par28\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Picture type:</strong> daily; documentary; black and white; art; portrait; landscape; abstract; report;</p> </li><li> <p id=\"Par29\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Picture theme:</strong> natural scenery; animals and insects; flowers and plants; still-life objects; character portrait; cultural construction; scene of stories; light rhythm;</p> </li><li> <p id=\"Par30\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Composition:</strong> nine-squared; diagonal; symmetry; frame; guide line; dynamic; triangle; photographic subtraction; special angle; repetition; vertical; curve; slash; centripetal; change; S-shape; open type; balance;</p> </li><li> <p id=\"Par31\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Means of expression:</strong> simplification; choice; comparison; contrast; scenery depth; background; lines; balance; motion; perspective; reflection;</p> </li><li> <p id=\"Par32\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Light and shade:</strong> backlight; soft light; capture light; appropriate exposure; contrast of exposure level; low angle light source; regional exposure; multicolor contrast;</p> </li><li> <p id=\"Par33\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Image style:</strong> traditional nostalgic, romantic, solemn and elegant, deep and solemn, easy dial, decorative arts, comparison of cool &amp; warm, open magic, scarce unique, novel and creative, human sensations, rhythm, non-mainstream</p> </li></ul></div></div><p id=\"Par34\" class=\"Para\">In order to synthesize tag information, the matrix should be transformed into questionnaire. Some experts in both design and photography assigned the tags shown above to the 574 samples based on certain principles explored in previous studies.</p><div id=\"Par35\" class=\"Para\">With the 574 samples and their tags, the matrix of metrical data was established, a measure method previously mentioned. The matrix was being imported to SPSS latter (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig4\">4</a></span>).<figure class=\"Figure\" id=\"Fig4\"><div class=\"MediaObject\" id=\"MO4\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig4_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig4_HTML.gif\" alt=\"Fig.\u00a04.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a04.</span> <p class=\"SimplePara\">Matrix of metrical data</p> </div></figcaption></figure></div></section></div></section><section id=\"Sec8\" tabindex=\"-1\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\"><span class=\"HeadingNumber\">4 </span>Result</h2><div class=\"content\"><section id=\"Sec9\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">4.1 </span>Result Evaluation of Image Feature Identification</h3><p id=\"Par36\" class=\"Para\">According to the design of research previously described, the research of image features mainly involves feature extraction of the samples. The extraction job includes:</p><p id=\"Par37\" class=\"Para\">Make quantitative analysis based on color attributes of the sample (sample pixel RGB value). The main research steps include extracting the dominant color tone. According to the specific features of samples, the composition of the picture usually differs in many ways. Some of them possess a conspicuous dominant color tone while others are composed of many colors. Whatever, the number of dominant color tones of certain sample is able to represent 80\u00a0% of its color information.</p><p id=\"Par38\" class=\"Para\">The representative color tone of samples is evolved from all dominant color tones, which is used to analyze similarity between samples.</p><p id=\"Par39\" class=\"Para\">The distance between the color tones, which occupies relatively larger proportion of dominant color tones, is calculated based on the composition of each sample.</p><div id=\"Par40\" class=\"Para\">Figure\u00a0<span class=\"InternalRef\"><a href=\"#Fig5\">5</a></span> illustrate the similarity of the positioning of color space, based on our calculation and analysis.<figure class=\"Figure\" id=\"Fig5\"><div class=\"MediaObject\" id=\"MO5\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig5_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig5_HTML.gif\" alt=\"Fig.\u00a05.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a05.</span> <p class=\"SimplePara\">The similarity of the positioning of color space. (Color figure online)</p> </div></figcaption></figure></div><div id=\"Par41\" class=\"Para\">Figure\u00a0<span class=\"InternalRef\"><a href=\"#Fig6\">6</a></span> illustrate the similarity analysis of dominant color tones, by the MDS multi-dimensional scaling function of themeDistComputingTool_v1<figure class=\"Figure\" id=\"Fig6\"><div class=\"MediaObject\" id=\"MO6\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig6_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig6_HTML.gif\" alt=\"Fig.\u00a06.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a06.</span> <p class=\"SimplePara\">Theme Color Position-1.</p> </div></figcaption></figure></div><div id=\"Par42\" class=\"Para\">In Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig7\">7</a></span>, it is obvious that all of the samples shows remarkable patterns on positioning distribution of dominant color tone similarity. Based on the distribution of scattered plots, a two element regression equation is obtained by two order curve fitting:<figure class=\"Figure\" id=\"Fig7\"><div class=\"MediaObject\" id=\"MO7\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig7_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig7_HTML.gif\" alt=\"Fig.\u00a07.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a07.</span> <p class=\"SimplePara\">Theme Color Position-2 (Color figure online)</p> </div></figcaption></figure></div><div id=\"Par43\" class=\"Para\"> <div id=\"Equa\" class=\"Equation EquationMathjax\"><div class=\"EquationContent\">$$ {\\text{y}} = - 0. 2 + - 0. 2 7*{\\text{x}} + 0. 5 3*{\\text{x}}^{ 2} $$</div></div> </div><div id=\"Par44\" class=\"Para\">To make the distribution pattern of the result more easily determined, researchers supplement information for Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig8\">8</a></span> and 574 dominant color tone palette which are also positioned to the corresponding scattered positions.<figure class=\"Figure\" id=\"Fig8\"><div class=\"MediaObject\" id=\"MO9\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig8_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig8_HTML.gif\" alt=\"Fig.\u00a08.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a08.</span> <p class=\"SimplePara\">Picture theme</p> </div></figcaption></figure></div><p id=\"Par45\" class=\"Para\">We found that despite the differences in properties and content among the 574 samples, a significant pattern exists in the features of visual cognition of dominant color tones. The pattern was represented by the mild gradient of brightness from darkness on the left to brightness on the right. However, no obvious pattern was recognized in vertical dimension. In addition, the significance of saturation in center and center-right areas in the U-shape curve area is higher than that in other areas.</p><p id=\"Par46\" class=\"Para\">To sum up, it is convincing that the 574 samples primarily reflects differences in saturation and color temperature in terms of color properties, based on the result of color space positioning analysis and dominant color tone similarity MDS analysis.</p></section><section id=\"Sec10\" tabindex=\"-1\" class=\"Section2 RenderAsSection2\"><h3 class=\"Heading\"><span class=\"HeadingNumber\">4.2 </span>Result Evaluation of Statistical Calculation</h3><p id=\"Par47\" class=\"Para\">Recall previous discussion, correspondence analysis is the main method in this research. The location map analysis, resulting from 574 samples in all dimensions, is discussed below. Among all the dimensions, abundance of color tones is particular interesting so that the first part of this section makes a comparison between it and other dimensions while the second part discusses results within the other dimensions.</p><p id=\"Par48\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Abundance of Color Tones Compare to Other Dimensions</strong> </p><p id=\"Par49\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Picture Theme.</em> Picture Theme The sig value is 1.000a, which indicates that there\u2019s no significant relation between picture theme and tone abundance. No typical pattern is recognized in the distribution of the sample from different topics. In addition, the theme of still life objects is rare in the sample.</p><div id=\"Par50\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Composition.</em> The sig value is 1.000a, one can see that most types of the composition is in a relatively concentrated manner while the diagonal type and curves type are relatively rare (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig9\">9</a></span>).<figure class=\"Figure\" id=\"Fig9\"><div class=\"MediaObject\" id=\"MO10\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig9_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig9_HTML.gif\" alt=\"Fig.\u00a09.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a09.</span> <p class=\"SimplePara\">Composition</p> </div></figcaption></figure></div><div id=\"Par51\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Means of Expression.</em> In this figure, excepting the line type, the performance is similar in the majority of the sample (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig10\">10</a></span>).<figure class=\"Figure\" id=\"Fig10\"><div class=\"MediaObject\" id=\"MO11\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig10_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig10_HTML.gif\" alt=\"Fig.\u00a010.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a010.</span> <p class=\"SimplePara\">Means of expression</p> </div></figcaption></figure></div><div id=\"Par52\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Light and Shade.</em> The sig value is 1.000a. There is no obvious correlation between lighting and tone abundance in this dimension. Meanwhile, low angle light source is more unique due to the special angle (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig11\">11</a></span>).<figure class=\"Figure\" id=\"Fig11\"><div class=\"MediaObject\" id=\"MO12\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig11_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig11_HTML.gif\" alt=\"Fig.\u00a011.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a011.</span> <p class=\"SimplePara\">Lights and shade</p> </div></figcaption></figure></div><div id=\"Par53\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Image Style.</em> The sig value is 1.000a. Image style and tone abundance have no significant correlation. However, the rhythm is relatively rare (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig12\">12</a></span>).<figure class=\"Figure\" id=\"Fig12\"><div class=\"MediaObject\" id=\"MO13\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig12_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig12_HTML.gif\" alt=\"Fig.\u00a012.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a012.</span> <p class=\"SimplePara\">Image style</p> </div></figcaption></figure></div><p id=\"Par54\" class=\"Para\"> <strong class=\"EmphasisTypeBold \">Results Within Other Dimensions.</strong> Overall, three common features were found through all 574 samples. Firstly, in terms of the type, pictures about scenery or daily lives ranked the highest; then follows art, documentary and portrait; report and abstract had the least quantity. Secondly, for the composition, most samples were showed in a way of nine-squared or symmetry, which is associated with human aesthetic physiological characteristics. People like pictures which are concisely composed with a certain guidance or restriction, such as radial line, leading line, diagonal, or frame. The third common feature lies in image style. The most popular pictures are usually unique and relaxing. Nostalgic, romantic, solemn, aesthetic and novel ingredients are welcome as well. In contrast, popular pictures are scarcely in themes of rhythm, contrast or humanity.</p><p id=\"Par55\" class=\"Para\">The four results of specific analysis are shown in following figures.</p><p id=\"Par56\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Picture Type Compare to Image Style.</em> The correspondence analysis of picture type and styles, with 574 effective samples and Sig value zero, indicating that there is a significant correlation between the type and the style.</p><div id=\"Par57\" class=\"Para\">The common aesthetic taste of inclining scenery and daily type of pictures was very likely being developed along with the evolution of human beings. Analysis of this type indicates that ancient prairie scenery, composed by fresh grass, low jungles and winding streams, gives comfortable and congruent feelings to people living in nearly all places. People often find senses of identity from documentary and portrait paintings, making it the second popular type. Abstract pictures are only appreciated by a small group of people (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig13\">13</a></span>).<figure class=\"Figure\" id=\"Fig13\"><div class=\"MediaObject\" id=\"MO14\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig13_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig13_HTML.gif\" alt=\"Fig.\u00a013.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a013.</span> <p class=\"SimplePara\">Picture type&amp;Image style</p> </div></figcaption></figure></div><p id=\"Par58\" class=\"Para\">The result also shows that there\u2019s a common mapping between image content type and means of expression. Sceneries are normally expressed through romantic, solemn, elegant or temperature contrasting styles, portraits by nostalgic and black-white ways and artistic pictures by decorating, novel, open magical ones.</p><div id=\"Par59\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Composition Compare to Image Style.</em> In the correspondence analysis of this comparison, 562 effective samples leaded to a sig value of 0.005, suggesting a significant connection between image style and composition (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig14\">14</a></span>).<figure class=\"Figure\" id=\"Fig14\"><div class=\"MediaObject\" id=\"MO15\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig14_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig14_HTML.gif\" alt=\"Fig.\u00a014.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a014.</span> <p class=\"SimplePara\">Composition&amp;Image style</p> </div></figcaption></figure></div><p id=\"Par60\" class=\"Para\">In the history of human aesthetic, nine-squared and symmetric have occupied their place in composition. Famous historical buildings, from Gothic to Chinese style, are designed to be strictly symmetric. Centripetal, guide-line, diagonal and frame are also prevailing metamorphism of symmetric.</p><p id=\"Par61\" class=\"Para\">The paring of romantic with symmetric, traditional with vertical, nine-squared with temperature contrast, can serve as a good reference for future composition designing.</p><div id=\"Par62\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Light and Shade Compare to Image Style.</em> Scarce unique and easy dial are the two most welcome styles. The pessimistic nature of deep and solemn and the direct definition of non-mainstream causes the lack of attraction to the majority (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig15\">15</a></span>).<figure class=\"Figure\" id=\"Fig15\"><div class=\"MediaObject\" id=\"MO16\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig15_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig15_HTML.gif\" alt=\"Fig.15.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.15.</span> <p class=\"SimplePara\">Light and shade&amp;Image style</p> </div></figcaption></figure></div><p id=\"Par63\" class=\"Para\">Considering both dimensions, there\u2019s significant relation between backlight and solemn, capture light and temperature contrast, regional exposure and elegant. Appropriate exposure is suitable for many styles, including romantic, human sensations, traditional nostalgic and easy dial.</p><div id=\"Par64\" class=\"Para\"> <em class=\"EmphasisTypeItalic \">Composition Compare to Light and Shade.</em> Soft light pictures typically adopt expressions of S-shape, triangle, open type and centripetal. Diagonal and guide-lines are mostly used in photographic subtraction, while appropriate exposure in balance. Soft light and contrast of exposure level are totally opposite shown in the figure, indicating the thorough difference (Fig.\u00a0<span class=\"InternalRef\"><a href=\"#Fig16\">16</a></span>).<figure class=\"Figure\" id=\"Fig16\"><div class=\"MediaObject\" id=\"MO17\"> <a href=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig16_HTML.gif\" target=\"_blank\" rel=\"noopener\"><span class=\"u-screenreader-only\">Open image in new window</span><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-40406-6_17/MediaObjects/427434_1_En_17_Fig16_HTML.gif\" alt=\"Fig.\u00a016.\" /></a> </div><figcaption class=\"Caption\" lang=\"en\"><div class=\"CaptionContent\"><span class=\"CaptionNumber\">Fig.\u00a016.</span> <p class=\"SimplePara\">Composition&amp;Light and shade</p> </div></figcaption></figure></div></section></div></section><section id=\"Sec11\" tabindex=\"-1\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\"><span class=\"HeadingNumber\">5 </span>Conclusion</h2><div class=\"content\"><p id=\"Par65\" class=\"Para\">By extracting features of the sample images, analyzing the contents of semantic tags, looking for common features in popular images which hold relatively high degree of users\u2019 attention, and studying the corresponding relationship between each label; this essay tends to figure out why users are paying more attention to landscape images. In addition, users favor composition balance, nine-squared format, with proper exposure, backlight or the way of capturing light. Besides, users also prefer the traditional nostalgia, deep dignified black and white photos or portraits; Photos they like range from lyrical romantic, lively, unique landscape to the daily theme; Over and above, users are also interested in innovative photos as well as open magic art photos.</p><p id=\"Par66\" class=\"Para\">These findings are significant for the construction of photo sharing site user knowledge. In the future, against such users who like sharing photos on these photos sharing websites, you can understand the relationship between the key themes of their favorite pictures, the composition and expression, light and shadow, style and tone. Designers can learn the preferences and needs of such users through first-hand detailed and reliable data to apply to other designs designed for this kind of user.</p><p id=\"Par67\" class=\"Para\">In this study, the method used is construction of user knowledge system by analyzing user behavior among those who like sharing pictures. This method can also be used in many other aspects of the behavior of keywords. For example, in the field of advertising communication, product packing design and all other users knowledge mining areas related to pictures.</p><p id=\"Par68\" class=\"Para\">In this study, the construction of the user knowledge mining method is different from the traditional method of user experience. As a result, it can be used in many aspects and fields to establish the user knowledge system based on general characteristics of different users\u2019 needs, concerns, and thus facilitating designers\u2019 working process. When identified certain feature of the keyword behavior of the user, designer can quickly draw from the user knowledge bank to find effective and usable research data for reference to aid their design decisions.</p><p id=\"Par69\" class=\"Para\">Mining and Construction of such a user\u2019s knowledge system can be time-consuming in the early stage. However, once the user knowledge bank has been set up, it will not only facilitate the designer to effectively understand the needs of users and help decision-making, but also makes it easier for multiple designers in one single design projects to understand the common goal. In this way, the design consistency among several designers can be ensured and it saves designers time in reducing communication costs and in the end largely improves the communication quality.</p><p id=\"Par70\" class=\"Para\">This study mainly introduces the user knowledge, image mining method. What remains to be analyzed is the construction of other points of the user knowledge, such as text and sound. It is an area which still worth further studying and forms general research methods and theories. These aspects can be used as subsequent supplementary research for user\u2019s knowledge system construction.</p><p id=\"Par71\" class=\"Para\">A well-established user database is built on both the traditional method and the innovative new one. Getting to understand users\u2019 need from multi-dimensional perspective of big data method as well as the traditional way of conducting interview, survey and focus group seems to be the new trend. However, this essay deems that the new method of construction is fundamental to this trend while combined with the traditional method will make it better.</p></div></section></div><section class=\"Section1 RenderAsSection1\" id=\"Bib1\" tabindex=\"-1\"><h2 class=\"Heading\">References</h2><div class=\"content\"><ol class=\"BibliographyWrapper\"><li class=\"Citation\"><div class=\"CitationNumber\">1.</div><div class=\"CitationContent\" id=\"CR1\">McDonald, J.E., Schvaneveldt, R.W.: The application of user knowledge to interface design. In: Cognitive Science and its Applications for Human-Computer Interaction, pp. 289\u2013338 (1988)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=McDonald%2C%20J.E.%2C%20Schvaneveldt%2C%20R.W.%3A%20The%20application%20of%20user%20knowledge%20to%20interface%20design.%20In%3A%20Cognitive%20Science%20and%20its%20Applications%20for%20Human-Computer%20Interaction%2C%20pp.%20289%E2%80%93338%20%281988%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">2.</div><div class=\"CitationContent\" id=\"CR2\">Blandford, A., Young, R.M.: Specifying user knowledge for the design of interactive systems. Softw. Eng. J. <strong class=\"EmphasisTypeBold \">11</strong>(6), 323\u2013333 (1996)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1049/sej.1996.0043\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Specifying%20user%20knowledge%20for%20the%20design%20of%20interactive%20systems&amp;author=A.%20Blandford&amp;author=RM.%20Young&amp;journal=Softw.%20Eng.%20J.&amp;volume=11&amp;issue=6&amp;pages=323-333&amp;publication_year=1996\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">3.</div><div class=\"CitationContent\" id=\"CR3\">De Rosis, F., Pizzutilo, S., Russo, A., et al.: Modeling the user knowledge by belief networks. User Model. User-Adap. Inter. <strong class=\"EmphasisTypeBold \">2</strong>(4), 367\u2013388 (1992)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1007/BF01101110\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Modeling%20the%20user%20knowledge%20by%20belief%20networks&amp;author=F.%20Rosis&amp;author=S.%20Pizzutilo&amp;author=A.%20Russo&amp;journal=User%20Model.%20User-Adap.%20Inter.&amp;volume=2&amp;issue=4&amp;pages=367-388&amp;publication_year=1992\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">4.</div><div class=\"CitationContent\" id=\"CR4\">Tesch, D., Sobol, M.G., Klein, G., et al.: User and developer common knowledge: Effect on the success of information system development projects. Int. J. Project Manage. <strong class=\"EmphasisTypeBold \">27</strong>(7), 657\u2013664 (2009)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1016/j.ijproman.2009.01.002\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=User%20and%20developer%20common%20knowledge%3A%20Effect%20on%20the%20success%20of%20information%20system%20development%20projects&amp;author=D.%20Tesch&amp;author=MG.%20Sobol&amp;author=G.%20Klein&amp;journal=Int.%20J.%20Project%20Manage.&amp;volume=27&amp;issue=7&amp;pages=657-664&amp;publication_year=2009\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">5.</div><div class=\"CitationContent\" id=\"CR5\">Bevan, N.: What is the difference between the purpose of usability and user experience evaluation methods. In: Proceedings of the Workshop UXEM, 9, pp. 1\u20134 (2009)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Bevan%2C%20N.%3A%20What%20is%20the%20difference%20between%20the%20purpose%20of%20usability%20and%20user%20experience%20evaluation%20methods.%20In%3A%20Proceedings%20of%20the%20Workshop%20UXEM%2C%209%2C%20pp.%201%E2%80%934%20%282009%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">6.</div><div class=\"CitationContent\" id=\"CR6\">Vermeeren, A.P.O.S., Law, E.L.C., Roto, V., et al.: User experience evaluation methods: current state and development needs. In: Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries, pp. 521\u2013530. ACM (2010)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Vermeeren%2C%20A.P.O.S.%2C%20Law%2C%20E.L.C.%2C%20Roto%2C%20V.%2C%20et%20al.%3A%20User%20experience%20evaluation%20methods%3A%20current%20state%20and%20development%20needs.%20In%3A%20Proceedings%20of%20the%206th%20Nordic%20Conference%20on%20Human-Computer%20Interaction%3A%20Extending%20Boundaries%2C%20pp.%20521%E2%80%93530.%20ACM%20%282010%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">7.</div><div class=\"CitationContent\" id=\"CR7\">Law, E.L.C., Roto, V., Hassenzahl, M., et al.: Understanding, scoping and defining user experience: a survey approach. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 719\u2013728. ACM (2009)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Law%2C%20E.L.C.%2C%20Roto%2C%20V.%2C%20Hassenzahl%2C%20M.%2C%20et%20al.%3A%20Understanding%2C%20scoping%20and%20defining%20user%20experience%3A%20a%20survey%20approach.%20In%3A%20Proceedings%20of%20the%20SIGCHI%20Conference%20on%20Human%20Factors%20in%20Computing%20Systems%2C%20pp.%20719%E2%80%93728.%20ACM%20%282009%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">8.</div><div class=\"CitationContent\" id=\"CR8\">Hassenzahl, M., Tractinsky, N.: User experience-a research agenda[J]. Behav. Inf. Technol. <strong class=\"EmphasisTypeBold \">25</strong>(2), 91\u201397 (2006)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1080/01449290500330331\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=User%20experience-a%20research%20agenda%5BJ%5D&amp;author=M.%20Hassenzahl&amp;author=N.%20Tractinsky&amp;journal=Behav.%20Inf.%20Technol.&amp;volume=25&amp;issue=2&amp;pages=91-97&amp;publication_year=2006\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">9.</div><div class=\"CitationContent\" id=\"CR9\">V\u00e4\u00e4n\u00e4nen-Vainio-Mattila, K., Roto, V., Hassenzahl, M.: Towards practical user experience evaluation methods. In: Law, E.L.-C., Bevan, N., Christou, G., Springett, M., L\u00e1rusd\u00f3ttir, M. (eds.) Meaningful Measures: Valid Useful User Experience Measurement, pp. 19\u201322 (2008)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=V%C3%A4%C3%A4n%C3%A4nen-Vainio-Mattila%2C%20K.%2C%20Roto%2C%20V.%2C%20Hassenzahl%2C%20M.%3A%20Towards%20practical%20user%20experience%20evaluation%20methods.%20In%3A%20Law%2C%20E.L.-C.%2C%20Bevan%2C%20N.%2C%20Christou%2C%20G.%2C%20Springett%2C%20M.%2C%20L%C3%A1rusd%C3%B3ttir%2C%20M.%20%28eds.%29%20Meaningful%20Measures%3A%20Valid%20Useful%20User%20Experience%20Measurement%2C%20pp.%2019%E2%80%9322%20%282008%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">10.</div><div class=\"CitationContent\" id=\"CR10\">Obrist, M., Roto, V., V\u00e4\u00e4n\u00e4nen-Vainio-Mattila, K.: User experience evaluation: do you know which method to use? In: CHI 2009 Extended Abstracts on Human Factors in Computing Systems, pp. 2763\u20132766. ACM (2009)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Obrist%2C%20M.%2C%20Roto%2C%20V.%2C%20V%C3%A4%C3%A4n%C3%A4nen-Vainio-Mattila%2C%20K.%3A%20User%20experience%20evaluation%3A%20do%20you%20know%20which%20method%20to%20use%3F%20In%3A%20CHI%202009%20Extended%20Abstracts%20on%20Human%20Factors%20in%20Computing%20Systems%2C%20pp.%202763%E2%80%932766.%20ACM%20%282009%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">11.</div><div class=\"CitationContent\" id=\"CR11\">Maguire, M.: Methods to support human-centred design. Int. J. Hum. Comput. Stud. <strong class=\"EmphasisTypeBold \">55</strong>(4), 587\u2013634 (2001)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1006/ijhc.2001.0503\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceZLBID\"><a class=\"gtm-reference\" data-reference-type=\"MATH\" target=\"_blank\" rel=\"noopener\" href=\"http://www.emis.de/MATH-item?0984.68616\"><span><span>zbMATH</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Methods%20to%20support%20human-centred%20design&amp;author=M.%20Maguire&amp;journal=Int.%20J.%20Hum.%20Comput.%20Stud.&amp;volume=55&amp;issue=4&amp;pages=587-634&amp;publication_year=2001\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">12.</div><div class=\"CitationContent\" id=\"CR12\">Fan, W., Bifet, A.: Mining big data: current status, and forecast to the future. ACM sIGKDD Explor. Newsl. <strong class=\"EmphasisTypeBold \">14</strong>(2), 1\u20135 (2013)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1145/2481244.2481246\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Mining%20big%20data%3A%20current%20status%2C%20and%20forecast%20to%20the%20future&amp;author=W.%20Fan&amp;author=A.%20Bifet&amp;journal=ACM%20sIGKDD%20Explor.%20Newsl.&amp;volume=14&amp;issue=2&amp;pages=1-5&amp;publication_year=2013\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">13.</div><div class=\"CitationContent\" id=\"CR13\">Fisher, D., DeLine, R., Czerwinski, M., et al.: Interactions with big data analytics. Interactions <strong class=\"EmphasisTypeBold \">19</strong>(3), 50\u201359 (2012)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceDOI\"><a class=\"gtm-reference\" data-reference-type=\"CrossRef\" target=\"_blank\" rel=\"noopener\" href=\"https://doi.org/10.1145/2168931.2168943\"><span><span>CrossRef</span></span></a></span><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Interactions%20with%20big%20data%20analytics&amp;author=D.%20Fisher&amp;author=R.%20DeLine&amp;author=M.%20Czerwinski&amp;journal=Interactions&amp;volume=19&amp;issue=3&amp;pages=50-59&amp;publication_year=2012\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">14.</div><div class=\"CitationContent\" id=\"CR14\">Sarmento, L., Carvalho, P., Silva, M.J., et al.: Automatic creation of a reference corpus for political opinion mining in user-generated content. In: Proceedings of the 1st International CIKM Workshop on Topic-Sentiment Analysis for Mass Opinion, pp. 29\u201336. ACM (2009)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Sarmento%2C%20L.%2C%20Carvalho%2C%20P.%2C%20Silva%2C%20M.J.%2C%20et%20al.%3A%20Automatic%20creation%20of%20a%20reference%20corpus%20for%20political%20opinion%20mining%20in%20user-generated%20content.%20In%3A%20Proceedings%20of%20the%201st%20International%20CIKM%20Workshop%20on%20Topic-Sentiment%20Analysis%20for%20Mass%20Opinion%2C%20pp.%2029%E2%80%9336.%20ACM%20%282009%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">15.</div><div class=\"CitationContent\" id=\"CR15\">Graham, J.: Flickr of idea on a gaming project led to photo website. USA Today, 27 (2006)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Graham%2C%20J.%3A%20Flickr%20of%20idea%20on%20a%20gaming%20project%20led%20to%20photo%20website.%20USA%20Today%2C%2027%20%282006%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">16.</div><div class=\"CitationContent\" id=\"CR16\">Miller, A.D., Edwards, W.K.: Give and take: a study of consumer photo-sharing culture and practice. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 347\u2013356. ACM (2007)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Miller%2C%20A.D.%2C%20Edwards%2C%20W.K.%3A%20Give%20and%20take%3A%20a%20study%20of%20consumer%20photo-sharing%20culture%20and%20practice.%20In%3A%20Proceedings%20of%20the%20SIGCHI%20Conference%20on%20Human%20Factors%20in%20Computing%20Systems%2C%20pp.%20347%E2%80%93356.%20ACM%20%282007%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">17.</div><div class=\"CitationContent\" id=\"CR17\">Liu, S.B., Palen, L., Sutton, J., et al.: In search of the bigger picture: The emergent role of on-line photo sharing in times of disaster. In: Proceedings of the Information Systems for Crisis Response and Management Conference (ISCRAM) (2008)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Liu%2C%20S.B.%2C%20Palen%2C%20L.%2C%20Sutton%2C%20J.%2C%20et%20al.%3A%20In%20search%20of%20the%20bigger%20picture%3A%20The%20emergent%20role%20of%20on-line%20photo%20sharing%20in%20times%20of%20disaster.%20In%3A%20Proceedings%20of%20the%20Information%20Systems%20for%20Crisis%20Response%20and%20Management%20Conference%20%28ISCRAM%29%20%282008%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">18.</div><div class=\"CitationContent\" id=\"CR18\">Sigurbj\u00f6rnsson, B., Van Zwol, R.: Flickr tag recommendation based on collective knowledge. In: Proceedings of the 17th International Conference on World Wide Web, pp. 327\u2013336. ACM (2008)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Sigurbj%C3%B6rnsson%2C%20B.%2C%20Van%20Zwol%2C%20R.%3A%20Flickr%20tag%20recommendation%20based%20on%20collective%20knowledge.%20In%3A%20Proceedings%20of%20the%2017th%20International%20Conference%20on%20World%20Wide%20Web%2C%20pp.%20327%E2%80%93336.%20ACM%20%282008%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">19.</div><div class=\"CitationContent\" id=\"CR19\">Mislove, A., Koppula, H.S., Gummadi, K.P., et al.: Growth of the flickr social network. In: Proceedings of the First Workshop on Online Social Networks, pp. 25\u201330. ACM (2008)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Mislove%2C%20A.%2C%20Koppula%2C%20H.S.%2C%20Gummadi%2C%20K.P.%2C%20et%20al.%3A%20Growth%20of%20the%20flickr%20social%20network.%20In%3A%20Proceedings%20of%20the%20First%20Workshop%20on%20Online%20Social%20Networks%2C%20pp.%2025%E2%80%9330.%20ACM%20%282008%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">20.</div><div class=\"CitationContent\" id=\"CR20\">Kennedy, L., Naaman, M., Ahern, S., et al.: How flickr helps us make sense of the world: context and content in community-contributed media collections. In: Proceedings of the 15th International Conference on Multimedia, pp. 631\u2013640. ACM (2007)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=Kennedy%2C%20L.%2C%20Naaman%2C%20M.%2C%20Ahern%2C%20S.%2C%20et%20al.%3A%20How%20flickr%20helps%20us%20make%20sense%20of%20the%20world%3A%20context%20and%20content%20in%20community-contributed%20media%20collections.%20In%3A%20Proceedings%20of%20the%2015th%20International%20Conference%20on%20Multimedia%2C%20pp.%20631%E2%80%93640.%20ACM%20%282007%29\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">21.</div><div class=\"CitationContent\" id=\"CR21\">Yongchang, J.: Knowledge architecture based on user experience: a review of the basic principles for knowledge architecture in web 2.0. J. China Soc. Sci. Techn. Inf. <strong class=\"EmphasisTypeBold \">5</strong>, 018 (2010)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"http://scholar.google.com/scholar_lookup?title=Knowledge%20architecture%20based%20on%20user%20experience%3A%20a%20review%20of%20the%20basic%20principles%20for%20knowledge%20architecture%20in%20web%202.0&amp;author=J.%20Yongchang&amp;journal=J.%20China%20Soc.%20Sci.%20Techn.%20Inf.&amp;volume=5&amp;pages=018&amp;publication_year=2010\"><span><span>Google Scholar</span></span></a></span></span></div></li><li class=\"Citation\"><div class=\"CitationNumber\">22.</div><div class=\"CitationContent\" id=\"CR22\">McGinn, J., Kotamraju, N.: Datadriven persona development. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 1521\u20131524.\u00a0ACM\u00a0(2008)<span class=\"Occurrences\"><span class=\"Occurrence OccurrenceGS\"><a target=\"_blank\" rel=\"noopener\" class=\"google-scholar-link gtm-reference\" data-reference-type=\"Google Scholar\" href=\"https://scholar.google.com/scholar?q=McGinn%2C%20J.%2C%20Kotamraju%2C%20N.%3A%20Datadriven%20persona%20development.%20In%3A%20Proceedings%20of%20the%20SIGCHI%20Conference%20on%20Human%20Factors%20in%20Computing%20Systems%2C%20pp.%201521%E2%80%931524.%C2%A0ACM%C2%A0%282008%29\"><span><span>Google Scholar</span></span></a></span></span></div></li></ol></div></section><section class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\" id=\"copyrightInformation\">Copyright information</h2><div class=\"ArticleCopyright content\"><div class=\"ChapterCopyright\">\u00a9\u00a0Springer International Publishing Switzerland\u00a02016</div></div></section><section id=\"authorsandaffiliations\" class=\"Section1 RenderAsSection1\"><h2 class=\"Heading\">Authors and Affiliations</h2><div class=\"content authors-affiliations u-interface\"><ul class=\"test-contributor-names\"><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors-affiliations__name\">Nan\u00a0Liang</span><ul class=\"authors-affiliations__indexes u-inline-list\" data-role=\"AuthorsIndexes\"><li data-affiliation=\"affiliation-1\">1</li></ul></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors-affiliations__name\">Jiaming\u00a0Zhong</span><ul class=\"authors-affiliations__indexes u-inline-list\" data-role=\"AuthorsIndexes\"><li data-affiliation=\"affiliation-1\">1</li></ul></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors-affiliations__name\">Di\u00a0Wang</span><ul class=\"authors-affiliations__indexes u-inline-list\" data-role=\"AuthorsIndexes\"><li data-affiliation=\"affiliation-1\">1</li></ul></li><li itemscope=\"\" itemtype=\"http://schema.org/Person\" class=\"u-mb-2 u-pt-4 u-pb-4\" itemprop=\"author\"><span itemprop=\"name\" class=\"authors-affiliations__name\">Liqun\u00a0Zhang</span><ul class=\"authors-affiliations__indexes u-inline-list\" data-role=\"AuthorsIndexes\"><li data-affiliation=\"affiliation-1\">1</li></ul><span class=\"author-information\"><span class=\"author-information__contact u-icon-before\"><a href=\"mailto:zhanglq@sjtu.edu.cn\" title=\"zhanglq@sjtu.edu.cn\" itemprop=\"email\" data-track=\"click\" data-track-action=\"Email author\" data-track-label=\"\">Email author</a></span></span></li></ul><ol class=\"test-affiliations\"><li class=\"affiliation\" data-test=\"affiliation-1\" data-affiliation-highlight=\"affiliation-1\" itemscope=\"\" itemtype=\"http://schema.org/Organization\"><span class=\"affiliation__count\">1.</span><span class=\"affiliation__item\"><span itemprop=\"department\" class=\"affiliation__department\">Institute of Design Management</span><span itemprop=\"name\" class=\"affiliation__name\">S.J.T.U.</span><span itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/PostalAddress\" class=\"affiliation__address\"><span itemprop=\"addressRegion\" class=\"affiliation__city\">Shanghai</span><span itemprop=\"addressCountry\" class=\"affiliation__country\">China</span></span></span></li></ol></div></section></div>", "                        </article>", "                        <aside class=\"section section--collapsible\" id=\"AboutThisContent\">", "    <h2 class=\"section__heading\" id=\"aboutcontent\">About this paper</h2>", "    <div class=\"section__content bibliographic-information\">", "        ", "        <div class=\"crossmark__adjacent\">", "            <dl class=\"citation-info u-highlight-target u-mb-16\" id=\"citeas\" tabindex=\"-1\">", "    <dt class=\"test-cite-heading\">", "        Cite this paper as:", "    </dt>", "    <dd id=\"citethis-text\">Liang N., Zhong J., Wang D., Zhang L. (2016) The Exploration of User Knowledge Architecture Based on Mining User Generated Contents \u2013 An Application Case of Photo-Sharing Website. In: Marcus A. (eds) Design, User Experience, and Usability: Technological Contexts. DUXU 2016. Lecture Notes in Computer Science, vol 9748. Springer, Cham. https://doi.org/10.1007/978-3-319-40406-6_17</dd>", "</dl>", "                <ul class=\"bibliographic-information__list bibliographic-information__list--inline\">", "        <li class=\"bibliographic-information__item\">", "            <span class=\"bibliographic-information__title\">First Online</span>", "            <span class=\"bibliographic-information__value u-overflow-wrap\">22 June 2016</span>", "        </li>", "        <li class=\"bibliographic-information__item\">", "            <span class=\"bibliographic-information__title\">DOI</span>", "            <span class=\"bibliographic-information__value u-overflow-wrap\" id=\"doi-url\">https://doi.org/10.1007/978-3-319-40406-6_17</span>", "        </li>", "            <li class=\"bibliographic-information__item\">", "                <span class=\"bibliographic-information__title\">Publisher Name</span>", "                <span class=\"bibliographic-information__value\" id=\"publisher-name\">Springer, Cham</span>", "            </li>", "            <li class=\"bibliographic-information__item\">", "                <span class=\"bibliographic-information__title\">Print ISBN</span>", "                <span class=\"bibliographic-information__value\" id=\"print-isbn\">978-3-319-40405-9</span>", "            </li>", "            <li class=\"bibliographic-information__item\">", "                <span class=\"bibliographic-information__title\">Online ISBN</span>", "                <span class=\"bibliographic-information__value\" id=\"electronic-isbn\">978-3-319-40406-6</span>", "            </li>", "                <li class=\"bibliographic-information__item\">", "            <span class=\"bibliographic-information__title\">eBook Packages</span>", "                <span class=\"bibliographic-information__value\" itemprop=\"genre\"><a id=\"ebook-package\" href=\"/search?facet-content-type&#x3D;%22Book%22&amp;package&#x3D;11645&amp;facet-start-year&#x3D;2016&amp;facet-end-year&#x3D;2016\">Computer Science</a></span>", "                <span class=\"bibliographic-information__value\" itemprop=\"genre\"><a id=\"ebook-package\" href=\"/search?facet-content-type&#x3D;%22Book%22&amp;package&#x3D;43710&amp;facet-start-year&#x3D;2016&amp;facet-end-year&#x3D;2016\">Computer Science (R0)</a></span>", "        </li>", "    </ul>", "            <ul class=\"bibliographic-information__list\">", "        <li class=\"bibliographic-information__item\">", "            <a id=\"reprintsandpermissions-link\" target=\"_blank\" rel=\"noopener\" href=\"https://s100.copyright.com/AppDispatchServlet?publisherName&#x3D;SpringerNature&amp;orderBeanReset&#x3D;true&amp;orderSource&#x3D;SpringerLink&amp;copyright&#x3D;Springer+International+Publishing+Switzerland&amp;author&#x3D;Nan+Liang%2C+Jiaming+Zhong%2C+Di+Wang+et+al&amp;contentID&#x3D;10.1007%2F978-3-319-40406-6_17&amp;endPage&#x3D;192&amp;publicationDate&#x3D;2016&amp;startPage&#x3D;180&amp;publication&#x3D;eBook&amp;title&#x3D;The+Exploration+of+User+Knowledge+Architecture+Based+on+Mining+User+Generated+Contents+%E2%80%93+An+Application+Case+of+Photo-Sharing+Website&amp;imprint&#x3D;Springer+International+Publishing+Switzerland\" title=\"Visit RightsLink for information about reusing this paper\" data-track=\"click\" data-track-action=\"Reprints and Permissions\" data-track-label=\"\">Reprints and Permissions</a>", "        </li>", "</ul>", "        </div>", "      ", "      ", "          ", "    </div>", "</aside>", "                        <div class=\"section section--collapsible uptodate-recommendations gtm-recommendations\">", "    <h2 class=\"uptodate-recommendations__title section__heading gtm-recommendations__title\" id=\"uptodaterecommendations\">Personalised recommendations</h2>", "    <div class=\"section__content\">", "        <div class=\"uptodate-recommendations__container\">", "             <link rel=\"uptodate-inline\" href=\"/springerlink-static/1923692707/css/recommendations.css\"/>", "        </div>", "    </div>", "</div>", "                                <div id=\"doubleclick-native-ad\" data-google-ad=\"native\"></div>", "                        ", "                <div class=\"sticky-banner sticky-banner--no-download  u-interface u-hide\" data-component=\"SpringerLink.StickyBanner\" data-namespace=\"hasButton\">", "                    <div class=\"sticky-banner__container\">", "                            <div class=\"citations\" data-component=\"SV.Dropdown\" data-namespace=\"citationsSticky\">", "        <h3 class=\"u-h4\" data-role=\"button-dropdown__title\">", "    <span>Cite</span>", "    <span class=\"hide-text-small\">paper</span>", "</h3>", "<ul class=\"citations__content\" data-role=\"button-dropdown__content\">", "    <li>", "        <a href=\"#citeas\" data-track=\"click\" data-track-action=\"Cite as link\" data-track-label=\"Cite dropdown\">How to cite?</a>", "    </li>", "        <li>", "            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;refman&amp;flavour&#x3D;citation\"", "               title=\"Download this paper&#39;s citation as a .RIS file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"RIS\">", "                <span class=\"citations__extension\" data-gtmlabel=\"RIS\">", "                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>", "                    .RIS", "                </span>", "                <span class=\"citations__types\">", "                        <span>", "                            Papers", "                        </span>", "                        <span>", "                            Reference Manager", "                        </span>", "                        <span>", "                            RefWorks", "                        </span>", "                        <span>", "                            Zotero", "                        </span>", "                </span>", "            </a>", "        </li>", "        <li>", "            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;endnote&amp;flavour&#x3D;citation\"", "               title=\"Download this paper&#39;s citation as a .ENW file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"ENW\">", "                <span class=\"citations__extension\" data-gtmlabel=\"ENW\">", "                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>", "                    .ENW", "                </span>", "                <span class=\"citations__types\">", "                        <span>", "                            EndNote", "                        </span>", "                </span>", "            </a>", "        </li>", "        <li>", "            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;bibtex&amp;flavour&#x3D;citation\"", "               title=\"Download this paper&#39;s citation as a .BIB file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"BIB\">", "                <span class=\"citations__extension\" data-gtmlabel=\"BIB\">", "                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>", "                    .BIB", "                </span>", "                <span class=\"citations__types\">", "                        <span>", "                            BibTeX", "                        </span>", "                        <span>", "                            JabRef", "                        </span>", "                        <span>", "                            Mendeley", "                        </span>", "                </span>", "            </a>", "        </li>", "</ul>", "    </div>", "                                <div>", "        <a class=\"c-button share-this test-shareby-sharelink-link\" data-test=\"shareable-link\" target=\"_blank\" rel=\"noopener\" href=\"/sharelink/10.1007/978-3-319-40406-6_17\" data-track=\"click\" data-track-action=\"Share via\" data-track-label=\"ShareLink\">", "            <span>Share</span>", "            <span class=\"hide-text-small\">paper</span>", "        </a>", "    </div>", "                    </div>", "                </div>", "                    </div>", "                    <aside class=\"main-sidebar-right u-interface\">", "                        <div data-role=\"sticky-wrapper\">", "                            <div class=\"main-sidebar-right__content u-composite-layer\" data-component=\"SpringerLink.StickySidebar\">", "                                <div class=\"article-actions\" id=\"article-actions\">", "                                    <h2 class=\"u-screenreader-only\" aria-hidden=\"true\">Actions</h2>", "                                    <div class=\"u-js-hide u-js-show-two-col\">", "                                        ", "        ", "                                            <div class=\"citations\" data-component=\"SV.Dropdown\" data-namespace=\"citations\">", "        <h3 class=\"u-h4\" data-role=\"button-dropdown__title\">", "    <span>Cite</span>", "    <span class=\"hide-text-small\">paper</span>", "</h3>", "<ul class=\"citations__content\" data-role=\"button-dropdown__content\">", "    <li>", "        <a href=\"#citeas\" data-track=\"click\" data-track-action=\"Cite as link\" data-track-label=\"Cite dropdown\">How to cite?</a>", "    </li>", "        <li>", "            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;refman&amp;flavour&#x3D;citation\"", "               title=\"Download this paper&#39;s citation as a .RIS file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"RIS\">", "                <span class=\"citations__extension\" data-gtmlabel=\"RIS\">", "                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>", "                    .RIS", "                </span>", "                <span class=\"citations__types\">", "                        <span>", "                            Papers", "                        </span>", "                        <span>", "                            Reference Manager", "                        </span>", "                        <span>", "                            RefWorks", "                        </span>", "                        <span>", "                            Zotero", "                        </span>", "                </span>", "            </a>", "        </li>", "        <li>", "            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;endnote&amp;flavour&#x3D;citation\"", "               title=\"Download this paper&#39;s citation as a .ENW file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"ENW\">", "                <span class=\"citations__extension\" data-gtmlabel=\"ENW\">", "                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>", "                    .ENW", "                </span>", "                <span class=\"citations__types\">", "                        <span>", "                            EndNote", "                        </span>", "                </span>", "            </a>", "        </li>", "        <li>", "            <a href=\"//citation-needed.springer.com/v2/references/10.1007/978-3-319-40406-6_17?format&#x3D;bibtex&amp;flavour&#x3D;citation\"", "               title=\"Download this paper&#39;s citation as a .BIB file\" data-track=\"click\" data-track-action=\"Export citation\" data-track-label=\"BIB\">", "                <span class=\"citations__extension\" data-gtmlabel=\"BIB\">", "                    <svg class=\"u-vertical-align-absolute\" width=\"12\" height=\"14\" viewBox=\"0 0 12 14\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z\" fill=\"#004aa7\"/></svg>", "                    .BIB", "                </span>", "                <span class=\"citations__types\">", "                        <span>", "                            BibTeX", "                        </span>", "                        <span>", "                            JabRef", "                        </span>", "                        <span>", "                            Mendeley", "                        </span>", "                </span>", "            </a>", "        </li>", "</ul>", "    </div>", "                                                <div>", "        <a class=\"c-button share-this test-shareby-sharelink-link\" data-test=\"shareable-link\" target=\"_blank\" rel=\"noopener\" href=\"/sharelink/10.1007/978-3-319-40406-6_17\" data-track=\"click\" data-track-action=\"Share via\" data-track-label=\"ShareLink\">", "            <span>Share</span>", "            <span class=\"hide-text-small\">paper</span>", "        </a>", "    </div>", "                                    </div>", "                                </div>", "                                <nav class=\"toc\" aria-label=\"article contents\">", "    <h2 class=\"u-screenreader-only\" aria-hidden=\"true\">Table of contents</h2>", "    <ul id=\"article-contents\" class=\"article-contents\" tabindex=\"-1\">", "            <li>", "                <a title=\"Conference paper\" href=\"#enumeration\"><span class=\"u-overflow-ellipsis\">Conference paper</span></a>", "            </li>", "            <li>", "                <a title=\"Abstract\" href=\"#Abs1\"><span class=\"u-overflow-ellipsis\">Abstract</span></a>", "            </li>", "            <li>", "                <a title=\"Introduction\" href=\"#Sec1\"><span class=\"u-overflow-ellipsis\">Introduction</span></a>", "            </li>", "            <li>", "                <a title=\"Methodology Description\" href=\"#Sec2\"><span class=\"u-overflow-ellipsis\">Methodology Description</span></a>", "            </li>", "            <li>", "                <a title=\"Case Study of Photo Sharing Websites\" href=\"#Sec5\"><span class=\"u-overflow-ellipsis\">Case Study of Photo Sharing Websites</span></a>", "            </li>", "            <li>", "                <a title=\"Result\" href=\"#Sec8\"><span class=\"u-overflow-ellipsis\">Result</span></a>", "            </li>", "            <li>", "                <a title=\"Conclusion\" href=\"#Sec11\"><span class=\"u-overflow-ellipsis\">Conclusion</span></a>", "            </li>", "            <li>", "                <a title=\"References\" href=\"#Bib1\"><span class=\"u-overflow-ellipsis\">References</span></a>", "            </li>", "            <li>", "                <a title=\"Copyright information\" href=\"#copyrightInformation\"><span class=\"u-overflow-ellipsis\">Copyright information</span></a>", "            </li>", "            <li>", "                <a title=\"Authors and Affiliations\" href=\"#authorsandaffiliations\"><span class=\"u-overflow-ellipsis\">Authors and Affiliations</span></a>", "            </li>", "            <li>", "                <a title=\"About this paper\" href=\"#aboutcontent\"><span class=\"u-overflow-ellipsis\">About this paper</span></a>", "            </li>", "    </ul>", "</nav>", "                            </div>", "                                <div class=\"skyscraper-ad u-hide\" data-google-ad=\"skyscraper\" data-gpt-hide-ad>", "        <div class=\"skyscraper-ad__wrapper\">", "            <p class=\"skyscraper-ad__label\">Advertisement</p>", "            <button class=\"skyscraper-ad__hide\" title=\"Hide this advertisement\" data-gpt-hide-ad-button data-track=\"click\" data-track-action=\"Hide advertisement\" data-track-label=\"\">Hide</button>", "            <div id=\"doubleclick-ad\" class=\"skyscraper-ad__ad\" data-gpt></div>", "        </div>", "    </div>", "                        </div>", "                    </aside>", "                </div>", "            </main>", "                <footer class=\"footer u-interface\">", "        <div class=\"footer__aside-wrapper\">", "            <div class=\"footer__content\">", "                <div class=\"footer__aside\">", "                    <p class=\"footer__strapline\">Over 10 million scientific documents at your fingertips</p>", "                                <div class=\"footer__edition\" data-component=\"SV.EditionSwitcher\">", "                                    <h3 class=\"u-hide\" data-role=\"button-dropdown__title\" data-btn-text=\"Switch between Academic &#38; Corporate Edition\">Switch Edition</h3>", "                                    <ul data-role=\"button-dropdown__content\">", "                                        <li  class=\"selected\"><a href=\"/siteEdition/link?previousUrl=/chapter/10.1007%2F978-3-319-40406-6_17&id=siteedition-academic-link\" id=\"siteedition-academic-link\">Academic Edition</a></li>", "                                        <li ><a href=\"/siteEdition/rd?previousUrl=/chapter/10.1007%2F978-3-319-40406-6_17&id=siteedition-corporate-link\" id=\"siteedition-corporate-link\">Corporate Edition</a></li>", "                                    </ul>", "                                </div>", "                </div>", "            </div>", "        </div>", "        <div class=\"footer__content\">", "            <ul class=\"footer__nav\">", "                <li>", "                    <a href=\"/\">Home</a>", "                </li>", "                <li>", "                    <a href=\"/impressum\">Impressum</a>", "                </li>", "                <li>", "                    <a href=\"/termsandconditions\">Legal information</a>", "                </li>", "                <li>", "                    <a href=\"/privacystatement\">Privacy statement</a>", "                </li>", "                <li>", "                    <a href=\"https://www.springernature.com/ccpa\">California privacy statement</a>", "                </li>", "                <li>", "                    <a href=\"/cookiepolicy\">How we use cookies</a>", "                </li>", "                <li>", "                    <a class=\"optanon-toggle-display\" href=\"javascript:void(0);\">Manage cookies/Do not sell my data</a>", "                </li>", "                <li>", "                    <a href=\"/accessibility\">Accessibility</a>", "                </li>", "                <li>", "                    <a href=\"https://support.springer.com/en/support/home\">FAQ</a>", "                </li>", "                <li>", "                    <a id=\"contactus-footer-link\" href=\"https://support.springer.com/en/support/solutions/articles/6000206179-contacting-us\">Contact us</a>", "                </li>", "                <li>", "                    <a href=\"https://www.springer.com/gp/shop/promo/affiliate/springer-nature\">Affiliate program</a>", "                </li>", "            </ul>", "            <a class=\"parent-logo\"", "               target=\"_blank\" rel=\"noopener\"", "               href=\"//www.springernature.com\"", "               title=\"Go to Springer Nature\">", "                <span class=\"u-screenreader-only\">Springer Nature</span>", "                <svg width=\"125\" height=\"12\" focusable=\"false\" aria-hidden=\"true\">", "                    <image width=\"125\" height=\"12\"", "                           src=\"/springerlink-static/1923692707/images/png/springernature.png\"", "                           xmlns:xlink=\"http://www.w3.org/1999/xlink\"", "                           xlink:href=\"/springerlink-static/1923692707/images/svg/springernature.svg\">", "                    </image>", "                </svg>", "            </a>", "            <p class=\"footer__copyright\">&copy; 2020 Springer Nature Switzerland AG. Part of <a target=\"_blank\" rel=\"noopener\" href=\"//www.springernature.com\">Springer Nature</a>.</p>", "                <p class=\"footer__user-access-info\">", "                    <span>Not logged in</span>", "                    <span>Not affiliated</span>", "                    <span>201.35.134.227</span>", "                </p>", "        </div>", "    </footer>", "        </div>", "        <script type=\"text/javascript\">", "    (function() {", "        var linkEl = document.querySelector('.js-ctm');", "        var scriptsList = [];", "        var polyfillFeatures = '';", "        window.SpringerLink = window.SpringerLink || {};", "        window.SpringerLink.staticLocation = '/springerlink-static/1923692707';", "        window.eventTrackerInstance = null;", "        if (window.matchMedia && window.matchMedia(linkEl.media).matches) {", "            (function(h){h.className = h.className.replace('no-js', 'js')})(document.documentElement);", "            polyfillFeatures = 'default,fetch,Promise,Object.setPrototypeOf,Object.entries,Number.isInteger,MutationObserver,startsWith,Array.prototype.includes,Array.from,IntersectionObserver';", "            scriptsList = [", "                'https://cdn.polyfill.io/v2/polyfill.min.js?features=' + polyfillFeatures + '&flags=gated',", "                window.SpringerLink.staticLocation + '/js/main.js'", "            ];", "            scriptsList.forEach(function(script) {", "                var tag = document.createElement('script');", "                tag.async = false;", "                tag.src = script;", "                document.body.appendChild(tag);", "            });", "        }", "    })();", "</script>", "    <script>", "    (function() {", "        var linkEl = document.querySelector('.js-ctm');", "        if (window.matchMedia && window.matchMedia(linkEl.media).matches) {", "            var scriptMathJax = document.createElement('script');", "            scriptMathJax.async = false;", "            scriptMathJax.src = '/springerlink-static/1923692707/js/mathJax.js';", "            var s0 = document.getElementsByTagName('script')[0];", "            s0.parentNode.insertBefore(scriptMathJax, s0);", "        }", "    })();", "</script>", "    <script type=\"text/javascript\" id=\"googletag-push\">", "        ", "            var adSlot = '270604982/springerlink/book/chapter';", "        ", "        var definedSlots = [", "                {slot: [728, 90], containerName: 'doubleclick-leaderboard-ad'},", "                {slot: [160, 600], containerName: 'doubleclick-ad'},", "            {slot: [2, 2], containerName: 'doubleclick-native-ad'}", "        ];", "    </script>", "        ", "        <span id=\"chat-widget\" class=\"u-hide\"></span>", "                    <noscript>", "                <img aria-hidden=\"true\" role=\"presentation\" src=\"https://ssl-springer.met.vgwort.de/na/vgzm.415900-10.1007-978-3-319-40406-6_17\" width='1' height='1' alt='' />", "            </noscript>", "        ", "    </body>", "</html>"]}